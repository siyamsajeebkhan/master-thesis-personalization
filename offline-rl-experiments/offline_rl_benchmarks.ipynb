{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-06 21:44.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int32')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(4,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(1,)])\u001b[0m\n",
      "\u001b[2m2024-02-06 21:44.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
      "\u001b[2m2024-02-06 21:44.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import d3rlpy\n",
    "\n",
    "# get CartPole dataset\n",
    "dataset, env = d3rlpy.datasets.get_cartpole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = dataset.episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_lengths = []\n",
    "for ep in episodes:\n",
    "    ep_lengths.append(ep.observations.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.min(ep_lengths), np.max(ep_lengths), np.mean(ep_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = \"../offline-rl-experiments/d3rlpy_data/cartpole_replay_v1.1.0.h5\"\n",
    "with h5py.File(f, \"r\") as h5:\n",
    "    observations = h5[\"observations\"][()]\n",
    "    actions = h5[\"actions\"][()]\n",
    "    rewards = h5[\"rewards\"][()]\n",
    "    terminals = h5[\"terminals\"][()]\n",
    "\n",
    "if \"episode_terminals\" in h5:\n",
    "    episode_terminals = h5[\"episode_terminals\"][()]\n",
    "else:\n",
    "    episode_terminals = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99866, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from d3rlpy.dataset import load_v1\n",
    "with open(\"../offline-rl-experiments/d3rlpy_data/cartpole_replay_v1.1.0.h5\", \"rb\") as f:\n",
    "    episodes = load_v1(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Episode' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mepisodes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobservations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Episode' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "episodes[0]['observations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ssk/Desktop/master-thesis/master-thesis-personalization/data/dt-datasets/movielens/train-test-sets/mlens-train-trajectories-movies-as-actions-reduced-from-768-to-32.pkl\"\n",
    "\n",
    "import pickle\n",
    "with open(data_path, \"rb\") as f:\n",
    "    episodes_mlens = pickle.load(f)\n",
    "\n",
    "# with open(data_path, \"r\") as f:\n",
    "#     observations = h5[\"observations\"][()]\n",
    "#     actions = h5[\"actions\"][()]\n",
    "#     rewards = h5[\"rewards\"][()]\n",
    "#     terminals = h5[\"terminals\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "observations_mlens = []\n",
    "observations_mlens = np.concatenate([ep['observations'] for ep in episodes_mlens])\n",
    "actions_mlens = np.concatenate([ep['actions'] for ep in episodes_mlens])\n",
    "rewards_mlens = np.concatenate([ep['rewards'] for ep in episodes_mlens])\n",
    "terminals_mlens = np.concatenate([ep['terminals'] for ep in episodes_mlens])\n",
    "\n",
    "timeouts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d3rlpy.dataset import EpisodeGenerator\n",
    "\n",
    "episode_generator = EpisodeGenerator(\n",
    "    observations=observations_mlens,\n",
    "    actions=actions_mlens,\n",
    "    rewards=rewards_mlens,\n",
    "    terminals=terminals_mlens,\n",
    "    timeouts=timeouts,\n",
    ")\n",
    "\n",
    "episodes_generated_mlens = episode_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-06 22:13.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(32,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(32,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float64')], shape=[(1,)])\u001b[0m\n",
      "\u001b[2m2024-02-06 22:13.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.CONTINUOUS: 1>\u001b[0m\n",
      "\u001b[2m2024-02-06 22:13.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m32\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from d3rlpy.dataset import ReplayBuffer, InfiniteBuffer\n",
    "\n",
    "dataset = ReplayBuffer(\n",
    "    InfiniteBuffer(),\n",
    "    episodes=episodes_generated_mlens,\n",
    "    transition_picker=None,\n",
    "    trajectory_slicer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.episodes[0].observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cql = d3rlpy.algos.CQLConfig().create(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random dataset for testing\n",
    "total_episodes = 100\n",
    "for i in range(total_episodes):\n",
    "    ep_length = np.random.randint(100)\n",
    "    \n",
    "    for j in ep_length:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CQL algorithm\n",
    "cql = d3rlpy.algos.DiscreteCQLConfig().create(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "cql.fit(\n",
    "    dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\n",
    "        'environment': d3rlpy.metrics.EnvironmentEvaluator(env), # evaluate with CartPole-v1 environment\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "d3rlpy.metrics.evaluate_qlearning_with_environment(cql, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous CQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3rlpy\n",
    "\n",
    "# prepare dataset\n",
    "dataset, env = d3rlpy.datasets.get_d4rl('hopper-medium-v0')\n",
    "\n",
    "# # prepare algorithm\n",
    "# cql = d3rlpy.algos.CQLConfig().create(device='cuda:0')\n",
    "\n",
    "# # train\n",
    "# cql.fit(\n",
    "#     dataset,\n",
    "#     n_steps=100000,\n",
    "#     evaluators={\"environment\": d3rlpy.metrics.EnvironmentEvaluator(env)},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.episodes[0].observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d4rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d3rlpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
