{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network for dimensionality reduction\n",
    "class DimensionReducer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DimensionReducer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        output = self.tanh(x)\n",
    "        return output\n",
    "\n",
    "# Specify input and output dimensions for reduction\n",
    "input_dim = 768  # BERT embedding size\n",
    "output_dim = 8  # Reduced dimensionality\n",
    "\n",
    "# Create the dimension reduction model\n",
    "reducer_model = DimensionReducer(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preloaded from disk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "movies_ratings_and_tags = pd.read_csv(\"../data/movies_ratings_and_tags_mlens_small.csv\")\n",
    "movies_ratings_and_tags.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current train and test trajectories with action space's shape 768\n",
    "import pickle\n",
    "with open(\"/home/ssk/Desktop/master-thesis/master-thesis-personalization/data/dt-datasets/movielens/train-test-sets/mlens-train-trajectories-movies-as-actions.pkl\", 'rb') as f:\n",
    "    train_trajectories = pickle.load(f)\n",
    "\n",
    "with open(\"/home/ssk/Desktop/master-thesis/master-thesis-personalization/data/dt-datasets/movielens/train-test-sets/mlens-test-trajectories-movies-as-actions.pkl\", 'rb') as f:\n",
    "    test_trajectories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "movie_embed_to_id = {}\n",
    "for traj in tqdm(train_trajectories):\n",
    "    user_id = traj['user_id']\n",
    "    movie_ids = (movies_ratings_and_tags[movies_ratings_and_tags['userId'] == user_id]['movieId']).tolist()\n",
    "    movie_embeddings = torch.from_numpy(traj['actions'])\n",
    "    embeddings_flattened = movie_embeddings.view(-1, input_dim)\n",
    "    reduced_embeddings = reducer_model(embeddings_flattened).detach().numpy()\n",
    "    traj['actions'] = reduced_embeddings\n",
    "    for (mid, red_embed) in zip(movie_ids, reduced_embeddings):\n",
    "        movie_embed_to_id[tuple(red_embed)] = mid\n",
    "\n",
    "for traj in tqdm(test_trajectories):\n",
    "    user_id = traj['user_id']\n",
    "    movie_ids = (movies_ratings_and_tags[movies_ratings_and_tags['userId'] == user_id]['movieId']).tolist()\n",
    "    movie_embeddings = torch.from_numpy(traj['actions'])\n",
    "    embeddings_flattened = movie_embeddings.view(-1, input_dim)\n",
    "    reduced_embeddings = reducer_model(embeddings_flattened).detach().numpy()\n",
    "    traj['actions'] = reduced_embeddings\n",
    "    for (mid, red_embed) in zip(movie_ids, reduced_embeddings):\n",
    "        movie_embed_to_id[tuple(red_embed)] = mid\n",
    "\n",
    "with open(f\"../data/dt-datasets/movielens/processed-data/movie_embed_with_shape_{output_dim}_to_id_mapping_with_tanh.pkl\", 'wb') as f:\n",
    "    pickle.dump(movie_embed_to_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"../data/dt-datasets/movielens/processed-data/movie_embed_with_shape_{output_dim}_to_id_mapping.pkl\", 'rb') as f:\n",
    "#     movie_embed_to_id = pickle.load(f)\n",
    "\n",
    "# Create a vocab of all movies and save\n",
    "all_actions = list(movie_embed_to_id.keys())\n",
    "action_vocab = np.array(all_actions)\n",
    "\n",
    "with open (f\"../data/dt-datasets/movielens/processed-data/action_vocab_of_shape_{output_dim}_with_tanh.pkl\", 'wb') as f:\n",
    "    pickle.dump(action_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trajectories[0]['actions'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'movies as actions' trajectories\n",
    "# Save the train and test trajectories as pickle files to load them later\n",
    "import pickle\n",
    "with open(f'../data/dt-datasets/movielens/train-test-sets/mlens-train-trajectories-movies-as-actions-reduced-from-{input_dim}-to-{output_dim}_with_tanh.pkl', 'wb') as f:\n",
    "    pickle.dump(train_trajectories, f)\n",
    "with open(f'../data/dt-datasets/movielens/train-test-sets/mlens-test-trajectories-movies-as-actions-reduced-from-{input_dim}-to-{output_dim}_with_tanh.pkl', 'wb') as f:\n",
    "    pickle.dump(test_trajectories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example group of vectors\n",
    "vectors = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "# Example single vector\n",
    "single_vector = np.array([2, 3, 4])\n",
    "\n",
    "# Calculate cosine similarity between the single vector and each vector in the group\n",
    "# Cosine similarity formula: dot product of vectors / (magnitude of vector1 * magnitude of vector2)\n",
    "# Using np.dot() for dot product and np.linalg.norm() for calculating magnitudes\n",
    "similarities = np.dot(vectors, single_vector) / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(single_vector))\n",
    "\n",
    "# The 'similarities' array now contains the cosine similarities between the single vector and each vector in the group\n",
    "print(\"Cosine similarities:\", similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example group of vectors\n",
    "vectors = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "# Example single vector\n",
    "single_vector = np.array([2, 3, 4])\n",
    "\n",
    "# Calculate cosine similarity between the single vector and each vector in the group\n",
    "similarities = np.dot(vectors, single_vector) / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(single_vector))\n",
    "\n",
    "# Find the index of the most similar vector\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "# Retrieve the most similar vector from the group\n",
    "most_similar_vector = vectors[most_similar_index]\n",
    "\n",
    "# The 'most_similar_vector' is the vector from the group most similar to the 'single_vector'\n",
    "print(\"Most similar vector:\", most_similar_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example group of vectors\n",
    "vectors = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "# Example single vector\n",
    "single_vector = np.array([2, 3, 4]).reshape(1, -1)  # Reshape to match sklearn input format\n",
    "\n",
    "# Calculate cosine similarity between the single vector and each vector in the group\n",
    "similarities = cosine_similarity(vectors, single_vector)\n",
    "\n",
    "# Find the index of the most similar vector\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "# Retrieve the most similar vector from the group\n",
    "most_similar_vector = vectors[most_similar_index]\n",
    "\n",
    "# The 'most_similar_vector' is the vector from the group most similar to the 'single_vector'\n",
    "print(\"Most similar vector:\", most_similar_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example groups of vectors\n",
    "group1 = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "group2 = np.array([\n",
    "    [2, 3, 4],\n",
    "    [5, 6, 7],\n",
    "    [8, 9, 10],\n",
    "    [11, 12, 13]\n",
    "])\n",
    "\n",
    "# Initialize an array to store the most similar vectors from group1 for each vector in group2\n",
    "most_similar_vectors_group1 = []\n",
    "\n",
    "# Iterate through each vector in group2\n",
    "for vec in group2:\n",
    "    # Calculate cosine similarity between the current vector in group2 and all vectors in group1\n",
    "    similarities = cosine_similarity([vec], group1)\n",
    "\n",
    "    # Find the index of the most similar vector in group1\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    \n",
    "    # Retrieve the most similar vector from group1\n",
    "    most_similar_vector_group1 = group1[most_similar_index]\n",
    "    \n",
    "    # Append the most similar vector from group1 to the list\n",
    "    most_similar_vectors_group1.append(most_similar_vector_group1)\n",
    "\n",
    "# Convert the list of most similar vectors to a NumPy array\n",
    "most_similar_vectors_group1 = np.array(most_similar_vectors_group1)\n",
    "\n",
    "# Display the most similar vectors from group1 for each vector in group2\n",
    "print(\"Most similar vectors from group1 for each vector in group2:\")\n",
    "print(most_similar_vectors_group1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.randn(20, 3)\n",
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 2, 3)\n",
    "a = a.view(-1, a.shape[2])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(vocab, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(a, vocab)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argmax(similarities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-similarities, axis=1)[:, :1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision-transformer-climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
