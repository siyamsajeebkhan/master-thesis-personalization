{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/q621464/Desktop/Thesis/code/decision-transformer-thesis\")\n",
    "sys.path.append(\"/home/q621464/Desktop/Thesis/code/decision-transformer-thesis/atari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "# make deterministic\n",
    "from atari.mingpt.utils import set_seed\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from atari.mingpt.model_atari import GPT, GPTConfig\n",
    "from atari.mingpt.trainer_atari import Trainer, TrainerConfig\n",
    "from atari.mingpt.utils import sample\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import blosc\n",
    "import argparse\n",
    "from atari.create_dataset import create_dataset\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Apply dimensionality reduction here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, seed=123, context_length=30, epochs=5, model_type='reward_conditioned', num_steps=500000, num_buffers=50, env='SmartClimate', batch_size=128, log_to_wandb=False, trajectories_per_buffer=10, train_data_dir='../atari/data-for-dt/smart-climate-train-trajectories-v2.pkl', test_data_dir='../atari/data-for-dt/smart-climate-test-trajectories-v2.pkl') -> None:\n",
    "        self.seed = seed\n",
    "        self.context_length = context_length\n",
    "        self.epochs = epochs\n",
    "        self.model_type = model_type\n",
    "        self.num_steps =num_steps\n",
    "        self.num_buffers = num_buffers\n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.log_to_wandb = log_to_wandb\n",
    "        self.trajectories_per_buffer = trajectories_per_buffer\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.dim_reductor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config(env='SmartClimate', epochs=30, seed=123, train_data_dir='../atari/data-for-dt/smart-climate-train-trajectories-v2.pkl')\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensionality(obss):\n",
    "    X_train = obss\n",
    "    # Data normalizationd\n",
    "    scaler = StandardScaler()\n",
    "    # Fit and transform the data to perform z-score normalization\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Initialize PCA with the desired number of components (e.g., None for all components)\n",
    "    pca = PCA(n_components=None)\n",
    "\n",
    "    # Fit and transform the training data using PCA\n",
    "    X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "\n",
    "    # Get the explained variance ratio\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    # Get the cumulative explained variance ratio\n",
    "    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "    # Set a threshold for the cumulative explained variance ratio (e.g., 95% or 99%)\n",
    "    threshold_variance = 0.95\n",
    "\n",
    "    # Determine the number of components required to achieve the threshold\n",
    "    n_components = np.argmax(cumulative_variance_ratio >= threshold_variance) + 1\n",
    "    print(f\"Number of selected components: {n_components}\")\n",
    "\n",
    "    # Reduce the dimensionality to the selected number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "    print(f\"Shape of the reeduced dimensionality dataset: {X_train_pca.shape}\")\n",
    "\n",
    "    obss_reduced = X_train_pca\n",
    "    return obss_reduced, pca\n",
    "    # X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, total_trajectories=8000):\n",
    "    with open(data_dir, 'rb') as f:\n",
    "        trajectories = pickle.load(f)[0:total_trajectories]\n",
    "    obss = []\n",
    "    actions = []\n",
    "    returns = [0]\n",
    "    done_idxs = []\n",
    "    stepwise_returns = []    \n",
    "    for traj in trajectories:\n",
    "        obss += traj['observations'].tolist()\n",
    "        actions += traj['actions'].tolist()\n",
    "        stepwise_returns += traj['rewards'].tolist()\n",
    "        done_idxs += [len(obss)]\n",
    "        returns += [0]\n",
    "\n",
    "    actions = np.array(actions)\n",
    "    returns = np.array(returns)\n",
    "    stepwise_returns = np.array(stepwise_returns)\n",
    "    done_idxs = np.array(done_idxs)\n",
    "\n",
    "    # -- create reward-to-go dataset\n",
    "    start_index = 0\n",
    "    rtg = np.zeros_like(stepwise_returns)\n",
    "    for i in done_idxs:\n",
    "        i = int(i)\n",
    "        curr_traj_returns = stepwise_returns[start_index:i]\n",
    "        for j in range(i-1, start_index-1, -1): # start from i-1\n",
    "            rtg_j = curr_traj_returns[j-start_index:i-start_index]\n",
    "            rtg[j] = sum(rtg_j)\n",
    "        start_index = i\n",
    "    print('max rtg is %d' % max(rtg))\n",
    "\n",
    "    # -- create timestep dataset\n",
    "    start_index = 0\n",
    "    timesteps = np.zeros(len(actions)+1, dtype=int)\n",
    "    print(f\"total done idx: {len(done_idxs)}\")\n",
    "    for i in done_idxs:\n",
    "        # print(f\"done_idx: {i}\")\n",
    "        i = int(i)\n",
    "        # print(f\"start_idx: {start_index}, i: {i}\")\n",
    "        timesteps[start_index:i+1] = np.arange(i+1 - start_index)\n",
    "        start_index = i+1\n",
    "    # print('max timestep is %d' % max(timesteps))\n",
    "    \n",
    "    # if apply_dim_reduction:\n",
    "    #     obss, dim_reductor = reduce_dimensionality(obss)\n",
    "    \n",
    "\n",
    "\n",
    "    return obss, actions, returns, done_idxs, rtg, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateActionReturnDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size, actions, done_idxs, rtgs, timesteps, mean=0, std=1):\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = max(actions) + 1 # TODO: needs to be changed. Does it change dynamically based on the sampled data?\n",
    "        self.data = data\n",
    "        self.actions = actions\n",
    "        self.done_idxs = done_idxs\n",
    "        self.rtgs = rtgs\n",
    "        self.timesteps = timesteps\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        block_size = self.block_size // 3\n",
    "        states = torch.tensor(np.array(self.data[idx:idx+block_size]), dtype=torch.float32).reshape(block_size, -1) # \n",
    "        # (block_size, 4*84*84)\n",
    "        \n",
    "        # print(f\"There are nan values in the dataloader's batch: {torch.isnan(states).any()}\")\n",
    "        # mean = torch.mean(states)\n",
    "        # std = torch.std(states)\n",
    "        states = (states - self.mean) / self.std\n",
    "        # print(f\"mean: {mean}, std: {std} of the batch\\n\")\n",
    "        # states = states / 255.\n",
    "        # print(f\"There are nan values in the dataloader's batch after normalization: {torch.isnan(states).any()}\")\n",
    "        actions = torch.tensor(self.actions[idx:idx+block_size], dtype=torch.long).unsqueeze(1) # (block_size, 1)\n",
    "        rtgs = torch.tensor(self.rtgs[idx:idx+block_size], dtype=torch.float32).unsqueeze(1)\n",
    "        timesteps = torch.tensor(self.timesteps[idx:idx+1], dtype=torch.int64).unsqueeze(1)\n",
    "        # print(f\"timesteps shape: {timesteps.shape}\")\n",
    "\n",
    "        return states, actions, rtgs, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensionality(obss):\n",
    "    X_train = obss\n",
    "    # Data normalizationd\n",
    "    scaler = StandardScaler()\n",
    "    # Fit and transform the data to perform z-score normalization\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Initialize PCA with the desired number of components (e.g., None for all components)\n",
    "    pca = PCA(n_components=None)\n",
    "\n",
    "    # Fit and transform the training data using PCA\n",
    "    X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "\n",
    "    # Get the explained variance ratio\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    # Get the cumulative explained variance ratio\n",
    "    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "    # Set a threshold for the cumulative explained variance ratio (e.g., 95% or 99%)\n",
    "    threshold_variance = 0.95\n",
    "\n",
    "    # Determine the number of components required to achieve the threshold\n",
    "    n_components = np.argmax(cumulative_variance_ratio >= threshold_variance) + 1\n",
    "    print(f\"Number of selected components: {n_components}\")\n",
    "\n",
    "    # Reduce the dimensionality to the selected number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "    print(f\"Shape of the reeduced dimensionality dataset: {X_train_pca.shape}\")\n",
    "\n",
    "    obss_reduced = X_train_pca\n",
    "    return obss_reduced, pca\n",
    "    # X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_head = trial.suggest_int('n_layer', 4, 8, step=2)\n",
    "# context_length = 30\n",
    "model_type = \"reward_conditioned\"\n",
    "batch_size = 128\n",
    "seed = 123\n",
    "env = \"SmartClimate\"\n",
    "# Load the val_dataset\n",
    "val_data_dir = \"../atari/data-for-dt/smart-climate-val-trajectories-v2.pkl\"\n",
    "# Create the dataset first\n",
    "obss, actions, returns, done_idxs, rtgs, timesteps = create_dataset(val_data_dir, total_trajectories=300)\n",
    "\n",
    "# Split your data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(obss, actions, test_size=0.1, random_state=123)\n",
    "X_train, dim_reductor = reduce_dimensionality(X_train)\n",
    "X_val = dim_reductor.transform(X_val)\n",
    "print(f\"shape of X_train: {X_train.shape} and X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_actions = sorted([action for action in actions])\n",
    "reduced_dataset_actions_str = [str(action) for action in reduced_dataset_actions]\n",
    "sns.histplot(reduced_dataset_actions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_actions = sorted([action for action in actions])\n",
    "full_dataset_actions_str = [str(action) for action in full_dataset_actions]\n",
    "sns.histplot(full_dataset_actions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the KL divergence between two probability distributions p and q.\n",
    "    KL(p || q) = sum(p(x) * log(p(x) / q(x)))\n",
    "    \"\"\"\n",
    "    print(p.shape, q.shape)\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "# Count occurrences of actions in each list\n",
    "counts_full_dataset = Counter(full_dataset_actions)\n",
    "counts_reduced_dataset = Counter(reduced_dataset_actions)\n",
    "\n",
    "# Get unique actions from both lists\n",
    "unique_actions = sorted(set(full_dataset_actions + reduced_dataset_actions))\n",
    "\n",
    "# Convert counts to probabilities by normalizing\n",
    "total_full_dataset = len(full_dataset_actions)\n",
    "total_reduced_dataset = len(reduced_dataset_actions)\n",
    "p = np.array([counts_full_dataset[action] / total_full_dataset for action in unique_actions])\n",
    "q = np.array([counts_reduced_dataset[action] / total_reduced_dataset for action in unique_actions])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.4901232\n"
     ]
    }
   ],
   "source": [
    "# Calculate KL divergence\n",
    "p = torch.rand(128, 30, 1)\n",
    "q = torch.rand(128, 30, 1)\n",
    "# p = p.squeeze(2).view(-1)\n",
    "# q = q.squeeze(2).view(-1)\n",
    "from scipy.stats import entropy\n",
    "# Calculate KL divergence\n",
    "kl_divergence = entropy(p, q)\n",
    "\n",
    "print(\"KL Divergence:\", kl_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3840])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.squeeze(2).view(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from your_pytorch_model import YourModel  # Import your PyTorch model\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters to be tuned by Optuna\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    num_hidden_units = trial.suggest_int('num_hidden_units', 32, 256, step=8)\n",
    "    context_length = trial.suggest_int('context_length', 10, 30, step=10)\n",
    "    n_layer = trial.suggest_int('n_layer', 4, 8, step=2)\n",
    "    # n_head = trial.suggest_int('n_head', 4, 8, step=2)\n",
    "\n",
    "    train_dataset = StateActionReturnDataset(X_train, context_length*3, y_train, done_idxs, rtgs, timesteps)\n",
    "    val_dataset = StateActionReturnDataset(X_val, context_length*3, y_val, done_idxs, rtgs, timesteps)\n",
    "    print(f\"vocab size: {train_dataset.vocab_size}\")\n",
    "    \n",
    "    print(len(train_dataset), len(val_dataset))\n",
    "    # Define the model here\n",
    "    mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=n_layer, n_head=8, n_embd=num_hidden_units, model_type=model_type, max_timestep=max(timesteps), input_dim=X_train.shape[1])\n",
    "    model = GPT(mconf)\n",
    "\n",
    "    # Train the model for a fixed number of epochs\n",
    "    epochs = 10\n",
    "    tconf = TrainerConfig(max_epochs=epochs, batch_size=batch_size, learning_rate=learning_rate, lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*context_length*3, num_workers=4, seed=seed, model_type=model_type, env=env, max_timestep=max(timesteps))\n",
    "\n",
    "    rtg = 100\n",
    "    max_ep_len = 100\n",
    "    trainer = Trainer(model, train_dataset, None, val_dataset, tconf, env, rtg=rtg, max_ep_len=max_ep_len, num_eval_episodes=1, dim_reductor=dim_reductor)\n",
    "    \n",
    "    trainer.train()\n",
    "    val_loss, val_accuracy = trainer.evaluate_model()\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    # Return the validation loss as the objective value to be minimized\n",
    "    return val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial), n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0003999625589556598, 'num_hidden_units': 208, 'context_length': 10, 'n_layer': 8}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "# learning_rate = best_params['learning_rate']\n",
    "# num_hidden_units = best_params['num_hidden_units']\n",
    "# learning_rate, num_hidden_units\n",
    "# # Train your final model using the best hyperparameters\n",
    "# final_model = model(num_hidden_units)\n",
    "# optimizer = optim.Adam(final_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model on the entire training data\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/optuna/visualization/_plotly_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_imports\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplotly_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1775235/700555580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_optimization_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/optuna/visualization/_optimization_history.py\u001b[0m in \u001b[0;36mplot_optimization_history\u001b[0;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \"\"\"\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0m_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0minfo_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_optimization_history_info_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/optuna/_imports.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  11.0\n",
      "Best Params: \n",
      "  learning_rate: 0.0003999625589556598\n",
      "  num_hidden_units: 208\n",
      "  context_length: 10\n",
      "  n_layer: 8\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"Best Score: \", trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/optuna/visualization/_plotly_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_imports\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplotly_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1775235/3096958464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_optimization_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/optuna/visualization/_optimization_history.py\u001b[0m in \u001b[0;36mplot_optimization_history\u001b[0;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \"\"\"\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0m_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0minfo_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_optimization_history_info_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/optuna/_imports.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=4, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 22, 24, 28, 287830), datetime_complete=datetime.datetime(2023, 7, 30, 22, 30, 51, 417171), params={'learning_rate': 0.0003999625589556598, 'num_hidden_units': 208, 'context_length': 10, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=4, value=None),\n",
       " FrozenTrial(number=5, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 22, 30, 51, 419067), datetime_complete=datetime.datetime(2023, 7, 30, 22, 32, 38, 470879), params={'learning_rate': 0.0009556379222695591, 'num_hidden_units': 32, 'context_length': 10, 'n_layer': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=5, value=None),\n",
       " FrozenTrial(number=7, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 22, 37, 35, 897014), datetime_complete=datetime.datetime(2023, 7, 30, 22, 44, 5, 544768), params={'learning_rate': 3.957953574829382e-05, 'num_hidden_units': 64, 'context_length': 30, 'n_layer': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=7, value=None),\n",
       " FrozenTrial(number=11, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 23, 0, 7, 301998), datetime_complete=datetime.datetime(2023, 7, 30, 23, 6, 49, 744445), params={'learning_rate': 0.0009171276708310204, 'num_hidden_units': 104, 'context_length': 20, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=11, value=None),\n",
       " FrozenTrial(number=15, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 23, 19, 35, 600552), datetime_complete=datetime.datetime(2023, 7, 30, 23, 26, 11, 91522), params={'learning_rate': 0.00017834318469852765, 'num_hidden_units': 216, 'context_length': 10, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=15, value=None),\n",
       " FrozenTrial(number=16, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 23, 26, 11, 93458), datetime_complete=datetime.datetime(2023, 7, 30, 23, 29, 54, 878642), params={'learning_rate': 0.0005492508089223301, 'num_hidden_units': 32, 'context_length': 20, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=16, value=None),\n",
       " FrozenTrial(number=20, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 30, 23, 45, 42, 86818), datetime_complete=datetime.datetime(2023, 7, 30, 23, 50, 51, 956872), params={'learning_rate': 0.0003252351801698886, 'num_hidden_units': 80, 'context_length': 20, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=20, value=None),\n",
       " FrozenTrial(number=25, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 31, 0, 6, 29, 679250), datetime_complete=datetime.datetime(2023, 7, 31, 0, 8, 50, 646125), params={'learning_rate': 0.00013809069235465118, 'num_hidden_units': 120, 'context_length': 10, 'n_layer': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=25, value=None),\n",
       " FrozenTrial(number=33, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 31, 0, 51, 7, 90046), datetime_complete=datetime.datetime(2023, 7, 31, 0, 54, 3, 312908), params={'learning_rate': 0.0009468416553179241, 'num_hidden_units': 80, 'context_length': 10, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=33, value=None),\n",
       " FrozenTrial(number=36, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 31, 1, 6, 53, 997476), datetime_complete=datetime.datetime(2023, 7, 31, 1, 22, 46, 288800), params={'learning_rate': 0.0004594924750730073, 'num_hidden_units': 256, 'context_length': 30, 'n_layer': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=36, value=None),\n",
       " FrozenTrial(number=37, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 31, 1, 22, 46, 290201), datetime_complete=datetime.datetime(2023, 7, 31, 1, 27, 2, 939524), params={'learning_rate': 0.00029479414086433145, 'num_hidden_units': 176, 'context_length': 10, 'n_layer': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=37, value=None),\n",
       " FrozenTrial(number=41, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 31, 1, 46, 20, 810723), datetime_complete=datetime.datetime(2023, 7, 31, 1, 53, 22, 561917), params={'learning_rate': 0.00019157349656404534, 'num_hidden_units': 232, 'context_length': 10, 'n_layer': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=41, value=None),\n",
       " FrozenTrial(number=47, state=TrialState.COMPLETE, values=[11.0], datetime_start=datetime.datetime(2023, 7, 31, 2, 27, 22, 219861), datetime_complete=datetime.datetime(2023, 7, 31, 2, 29, 26, 190219), params={'learning_rate': 0.0006475104172755222, 'num_hidden_units': 72, 'context_length': 10, 'n_layer': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'num_hidden_units': IntDistribution(high=256, log=False, low=32, step=8), 'context_length': IntDistribution(high=30, log=False, low=10, step=10), 'n_layer': IntDistribution(high=8, log=False, low=4, step=2)}, trial_id=47, value=None)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision-transformer-atari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
