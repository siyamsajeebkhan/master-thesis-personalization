{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from gym import utils\n",
    "import gym\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLens Dataset Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MovieLens dataset\n",
    "ML_LATEST_SMALL_DATA_ROOT_PATH = \"../data/dt-datasets/movielens/ml-latest-small\"\n",
    "ML_LATEST_DATA_ROOT_PATH = \"../data/dt-datasets/movielens/ml-latest\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the ML-latest-small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links shape: (9742, 3)\n",
      "movies shape: (9742, 3)\n",
      "ratings shape: (100836, 4)\n",
      "tags shape: (3683, 4)\n"
     ]
    }
   ],
   "source": [
    "links_df = pd.read_csv(os.path.join(ML_LATEST_SMALL_DATA_ROOT_PATH, \"links.csv\"))\n",
    "movies_df = pd.read_csv(os.path.join(ML_LATEST_SMALL_DATA_ROOT_PATH, \"movies.csv\"))\n",
    "ratings_df = pd.read_csv(os.path.join(ML_LATEST_SMALL_DATA_ROOT_PATH, \"ratings.csv\"))\n",
    "tags_df = pd.read_csv(os.path.join(ML_LATEST_SMALL_DATA_ROOT_PATH, \"tags.csv\"))\n",
    "print(f\"links shape: {links_df.shape}\\nmovies shape: {movies_df.shape}\\nratings shape: {ratings_df.shape}\\ntags shape: {tags_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the ML-latest-full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links_25m_df = pd.read_csv(os.path.join(ML_LATEST_DATA_ROOT_PATH, \"links.csv\"))\n",
    "# movies_25m_df = pd.read_csv(os.path.join(ML_LATEST_DATA_ROOT_PATH, \"movies.csv\"))\n",
    "# ratings_25m_df = pd.read_csv(os.path.join(ML_LATEST_DATA_ROOT_PATH, \"ratings.csv\"))\n",
    "# tags_25m_df = pd.read_csv(os.path.join(ML_LATEST_DATA_ROOT_PATH, \"tags.csv\"))\n",
    "# print(f\"links shape: {links_25m_df.shape}\\nmovies shape: {movies_25m_df.shape}\\nratings shape: {ratings_25m_df.shape}\\ntags shape: {tags_25m_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min no of rating: 20, max no of rating: 2698\n",
      "average rating per user: 165.30491803278687, median rating per user: 70.5\n",
      "number of users who rated less than 140 movies: 429\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data distribution of the rating count per user in the small dataset\n",
    "rating_count_per_user = ratings_df.groupby('userId')['movieId'].count().values\n",
    "print(f'min no of rating: {np.min(rating_count_per_user)}, max no of rating: {np.max(rating_count_per_user)}')\n",
    "print(f'average rating per user: {np.mean(rating_count_per_user)}, median rating per user: {np.median(rating_count_per_user)}')\n",
    "print(f'number of users who rated less than 140 movies: {(rating_count_per_user <= 140).sum()}')\n",
    "sns.histplot(data = rating_count_per_user)\n",
    "plt.show()\n",
    "# sns.boxplot(rating_count_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "3            4\n",
       "4            5\n",
       "         ...  \n",
       "9737    193581\n",
       "9738    193583\n",
       "9739    193585\n",
       "9740    193587\n",
       "9741    193609\n",
       "Name: movieId, Length: 9742, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['movieId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(userId         int64\n",
       " movieId        int64\n",
       " rating       float64\n",
       " timestamp      int64\n",
       " dtype: object,\n",
       " movieId      int64\n",
       " imdbId       int64\n",
       " tmdbId     float64\n",
       " dtype: object,\n",
       " userId        int64\n",
       " movieId       int64\n",
       " tag          object\n",
       " timestamp     int64\n",
       " dtype: object,\n",
       " movieId     int64\n",
       " title      object\n",
       " genres     object\n",
       " dtype: object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Types\n",
    "ratings_df.dtypes, links_df.dtypes, tags_df.dtypes, movies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data distribution of the rating count per user in the large dataset\n",
    "# rating_count_per_user = ratings_25m_df.groupby('userId')['movieId'].count().values\n",
    "# print(f'min no of rating: {np.min(rating_count_per_user)}, max no of rating: {np.max(rating_count_per_user)}')\n",
    "# print(f'average rating per user: {np.mean(rating_count_per_user)}, median rating per user: {np.median(rating_count_per_user)}')\n",
    "\n",
    "# rating_count_less_than_140 = (rating_count_per_user <= 140).sum()\n",
    "# print(f'number of users who rated less than 140 movies: {rating_count_less_than_140} which is {(rating_count_less_than_140 / ratings_25m_df.userId.unique().shape[0]) * 100}% of the users.')\n",
    "# sns.histplot(data = rating_count_per_user, bins=100)\n",
    "# plt.show()\n",
    "# # sns.boxplot(rating_count_per_user)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies_df['title'].unique().shape[0])\n",
    "\n",
    "# Find the duplicated movie titles\n",
    "duplicated_movies = movies_df[movies_df['title'].duplicated(keep=False)].sort_values(by=['title', 'movieId'])\n",
    "\n",
    "# Some movies have additional genres, that's why the duplicates\n",
    "# Merge the genres, keep the ID of the one that has the highest number\n",
    "# of genres, create a map of the old and new id\n",
    "# drop the row with the least genre after merging\n",
    "duplicated_movie_titles = duplicated_movies['title'].unique()\n",
    "movie_ids_to_remove = duplicated_movies['movieId'].values\n",
    "movie_indices_to_remove = duplicated_movies.index.values\n",
    "id_mapping = {}\n",
    "resolved_movies = []\n",
    "for title in duplicated_movie_titles:\n",
    "    movie_ids = duplicated_movies[duplicated_movies['title'] == title]['movieId'].values\n",
    "    genre_groups = duplicated_movies[duplicated_movies['title'] == title]['genres'].values\n",
    "\n",
    "    for i in range(1, len(movie_ids)):\n",
    "        id_mapping[movie_ids[i]] = movie_ids[0]\n",
    "    merged_genres = set()\n",
    "    for genre_grp in genre_groups:\n",
    "        genres = genre_grp.split('|')\n",
    "        merged_genres = merged_genres.union(set(genres))\n",
    "    merged_genres = list(merged_genres)\n",
    "    genres_mixed = \"\"\n",
    "    for (i, g) in enumerate(merged_genres):\n",
    "        if i != len(merged_genres)-1:\n",
    "            genres_mixed += g + \"|\"\n",
    "        else:\n",
    "            genres_mixed += g\n",
    "\n",
    "    resolved_movies.append({'movieId': movie_ids[0], 'title': title, 'genres': genres_mixed})\n",
    "\n",
    "pd.DataFrame(resolved_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now remove the duplicate movies from the movies_df\n",
    "print(f\"Shape before rmeoving: {movies_df.shape}\")\n",
    "movies_df = movies_df.drop(movie_indices_to_remove)\n",
    "print(f\"Shape after rmeoving: {movies_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now concatenate the movies_df with removed movies and the merged_genres movies\n",
    "movies_df = pd.concat([movies_df, pd.DataFrame(resolved_movies)], ignore_index=True)\n",
    "print(movies_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to replace the removed movie ids in the ratings_df\n",
    "# and also in the tags_df\n",
    "ratings_df.head()\n",
    "ratings_df_copy = ratings_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ids with the id_mapping\n",
    "ratings_df_copy['movieId'] = ratings_df_copy['movieId'].replace(id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the duplicates\n",
    "ratings_df_copy[ratings_df_copy[['userId', 'movieId']].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_copy = ratings_df_copy.drop_duplicates(['userId', 'movieId', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one movie with two different ratings from the same user\n",
    "ratings_df_copy[ratings_df_copy[['userId', 'movieId']].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop the one with the lowest rating\n",
    "ratings_df = ratings_df_copy.drop([11241])\n",
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no more duplicates\n",
    "ratings_df[ratings_df[['userId', 'movieId']].duplicated(keep=False)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to replace the removed movie ids in the tags_df\n",
    "tags_df_copy = tags_df.copy()\n",
    "tags_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ids first with the id_mapping\n",
    "tags_df_copy['movieId'] = tags_df_copy['movieId'].replace(id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the duplicates\n",
    "tags_df_copy[tags_df_copy[['userId', 'movieId']].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results suggest that there are some outliers in the dataset\n",
    "tags_df_copy.groupby(['userId'])['movieId'].count().mean(), tags_df_copy.groupby(['userId'])['movieId'].count().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of tags per user per movie\n",
    "tags_df_copy.groupby(['userId', 'movieId']).count()['tag'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier: user 599 provided 173 tags for the movie 296\n",
    "print(f\"name of the movie: {movies_df[movies_df['movieId'] == 296]['title'].values[0]}\")\n",
    "tags_df[(tags_df['userId'] == 599) & (tags_df['movieId'] == 296)].sort_values(by='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_df['tag'] = tags_df['tag'].str.lower()\n",
    "tags_df['tag'] = tags_df['tag'].str.lower().astype(str)\n",
    "\n",
    "# Grouping by 'movieId' and 'userId' and aggregating tags\n",
    "tags_df_merged = tags_df.groupby(['movieId', 'userId'])['tag'].agg(lambda x: '|'.join(x)).reset_index()\n",
    "tags_df_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the movies and ratings dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_and_ratings = pd.merge(movies_df, ratings_df, on='movieId')\n",
    "movies_and_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_and_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any duplicate\n",
    "print(movies_and_ratings.duplicated().sum())\n",
    "\n",
    "print(movies_and_ratings.isna().sum())\n",
    "movies_and_ratings[movies_and_ratings[['movieId', 'userId']].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_and_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any null values\n",
    "movies_and_ratings['userId'].isna().sum(),  movies_and_ratings['movieId'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the userIds are present in the merged df as well\n",
    "sorted(ratings_df.userId.unique()) ==  sorted(movies_and_ratings.userId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the movie ratings by userId and timestamp in an ascending manner\n",
    "movies_and_ratings = movies_and_ratings.sort_values(by=['userId', 'timestamp'])\n",
    "movies_and_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the different rating values\n",
    "sorted(movies_and_ratings['rating'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many different genres do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = np.unique(np.concatenate(movies_and_ratings['genres'].apply(lambda g: g.split(\"|\")).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_genres = movies_and_ratings['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which genre the user rated the most\n",
    "2. Average rating of the user\n",
    "3. Average rating per genre\n",
    "4. Last 10 ratings\n",
    "5. Last 10 rated movies\n",
    "6. Which genre of movies does the user like the most?\n",
    "7. Number of rated movies per genres\n",
    "8. Average Rating per genre\n",
    "9. Total genres rated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Movielens dataset can be used to create a variety of personal features for movie recommendation to users. These features can be used to capture the specific interests and preferences of individual users. Here are some examples of personal features that can be created from the Movielens dataset:\n",
    "\n",
    "**Genre preferences:**\n",
    "\n",
    "* **Top genres:** Identify the genres of movies that a user has rated highly in the past.\n",
    "\n",
    "* **Genre diversity:** Measure the diversity of genres in a user's ratings. This can be used to identify users who are open to trying new genres.\n",
    "\n",
    "* **Genre consistency:** Calculate the consistency of a user's genre preferences. This can be used to identify users who have strong preferences for specific genres.\n",
    "\n",
    "**Director preferences:**\n",
    "\n",
    "* **Top directors:** Identify the directors of movies that a user has rated highly in the past.\n",
    "\n",
    "* **Director diversity:** Measure the diversity of directors in a user's ratings. This can be used to identify users who are open to watching movies by new directors.\n",
    "\n",
    "* **Director consistency:** Calculate the consistency of a user's director preferences. This can be used to identify users who have strong preferences for specific directors.\n",
    "\n",
    "**Actor preferences:**\n",
    "\n",
    "* **Top actors:** Identify the actors in movies that a user has rated highly in the past.\n",
    "\n",
    "* **Actor diversity:** Measure the diversity of actors in a user's ratings. This can be used to identify users who are open to watching movies with new actors.\n",
    "\n",
    "* **Actor consistency:** Calculate the consistency of a user's actor preferences. This can be used to identify users who have strong preferences for specific actors.\n",
    "\n",
    "**Rating tendencies:**\n",
    "\n",
    "* **Average rating:** Calculate the average rating that a user has given to movies in the past.\n",
    "\n",
    "* **Rating variability:** Measure the variability of a user's ratings. This can be used to identify users who are consistent in their ratings and users who are more open to giving extremes.\n",
    "\n",
    "* **Rating biases:** Identify any biases in a user's ratings, such as a tendency to give higher ratings to movies with specific genres or actors.\n",
    "\n",
    "**Temporal patterns:**\n",
    "\n",
    "* **Rating frequency:** Measure the frequency with which a user rates movies. This can be used to identify users who are more active in rating movies.\n",
    "\n",
    "* **Rating trends:** Identify any trends in a user's ratings over time, such as a shift in preferences or a decrease in activity.\n",
    "\n",
    "* **Seasonality:** Analyze whether a user's ratings are influenced by seasons or holidays.\n",
    "\n",
    "By creating these personal features, you can develop a more personalized movie recommendation system that takes into account the specific interests and preferences of individual users. This can lead to more engaging and relevant recommendations for your users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by user\n",
    "grouped_df = movies_and_ratings.groupby('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the genres for each movie for each user\n",
    "per_user_genre_counts = {}\n",
    "all_genre_count_dict = {f'{genre}_count': 0 for genre in all_genres}\n",
    "\n",
    "for user_id, user_df in grouped_df:\n",
    "    user_df['genres_splitted'] = user_df['genres'].str.split('|')\n",
    "    genre_counts = all_genre_count_dict.copy()\n",
    "\n",
    "    # Create separate columns for each genre\n",
    "    for genres, rating in zip(user_df['genres_splitted'], ratings):\n",
    "        for gen in genres:\n",
    "            if f'{gen}_count' in genre_counts:\n",
    "                genre_counts[f'{gen}_count'] += 1\n",
    "            else:\n",
    "                genre_counts[f'{gen}_count'] = 1\n",
    "\n",
    "    \n",
    "    per_user_genre_counts[user_id] = genre_counts\n",
    "\n",
    "# Extract the genres for each movie for each user\n",
    "per_user_genre_rating_sum = {}\n",
    "all_genre_rating_sum_dict = {f'{genre}_rating_sum': 0 for genre in all_genres}\n",
    "for user_id, user_df in grouped_df:\n",
    "    user_df['genres_splitted'] = user_df['genres'].str.split('|')\n",
    "    ratings = user_df['rating'].tolist()\n",
    "\n",
    "    genre_rating_sums = all_genre_rating_sum_dict.copy()\n",
    "\n",
    "    # Create separate columns for each genre\n",
    "    for genres, rating in zip(user_df['genres_splitted'], ratings):\n",
    "        for gen in genres:\n",
    "            if f'{gen}_rating_sum' in genre_rating_sums:\n",
    "                genre_rating_sums[f'{gen}_rating_sum'] += rating\n",
    "            else:\n",
    "                genre_rating_sums[f'{gen}_rating_sum'] = rating\n",
    "\n",
    "    per_user_genre_rating_sum[user_id] = genre_rating_sums\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most rated genres per user\n",
    "most_rated_genre_per_user = {}\n",
    "per_user_genre_counts_copy = per_user_genre_counts.copy()\n",
    "for user_id in per_user_genre_counts_copy:\n",
    "    genre_counts = per_user_genre_counts_copy[user_id]\n",
    "    most_rated_genre_with_count = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)[0]\n",
    "    # print(most_rated_genre_with_count)\n",
    "    most_rated_genre = most_rated_genre_with_count[0].split('_')[0]\n",
    "    # print(most_rated_genre)\n",
    "    most_rated_genre_per_user[user_id] = most_rated_genre\n",
    "most_rated_genre_per_user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_rated_genre_per_user_df = pd.DataFrame(most_rated_genre_per_user.items(), columns=['userId', 'most_rated_genre'])\n",
    "most_rated_genre_per_user_df['most_rated_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest, lowest and average rating per user\n",
    "stat_feat_per_user = []\n",
    "for user_id, user_df in grouped_df:\n",
    "    highest_rating = user_df['rating'].max()\n",
    "    lowest_rating = user_df['rating'].min()\n",
    "    average_rating = user_df['rating'].mean()\n",
    "    stat_feat_per_user.append({'userId': user_id, 'highest_rating': highest_rating, 'lowest_rating': lowest_rating, 'avg_rating': average_rating})\n",
    "statistical_features_df = pd.DataFrame(stat_feat_per_user)\n",
    "statistical_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_user_avg_genre_ratings = []\n",
    "avg_genre_rating_init = {f'{genre}_avg_rating': 0 for genre in all_genres}\n",
    "# all_genre_count_dict = {f'{genre}_count': 0 for genre in all_genres}\n",
    "for user_id in per_user_genre_rating_sum:\n",
    "    avg_genre_rating = avg_genre_rating_init.copy()\n",
    "    # print(f\"user_id: {user_id}\")\n",
    "    genre_counts_per_user = per_user_genre_counts[user_id].copy()\n",
    "    genre_rating_sums_per_user = per_user_genre_rating_sum[user_id].copy()\n",
    "    for genre in all_genres:\n",
    "        if genre_counts_per_user[f'{genre}_count'] == 0:\n",
    "            avg_genre_rating[f'{genre}_avg_rating'] = 0\n",
    "        else:\n",
    "            avg_genre_rating[f'{genre}_avg_rating'] = genre_rating_sums_per_user[f'{genre}_rating_sum'] / genre_counts_per_user[f'{genre}_count']\n",
    "\n",
    "    avg_genre_rating['userId'] = user_id\n",
    "    print(avg_genre_rating)\n",
    "    per_user_avg_genre_ratings.append(avg_genre_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "most_liked_genres_per_user = {}\n",
    "per_user_avg_genre_ratings_copy = deepcopy(per_user_avg_genre_ratings)\n",
    "for dictt in per_user_avg_genre_ratings_copy:\n",
    "    user_id = dictt['userId']\n",
    "    dictt.pop('userId')\n",
    "    most_liked_genre = sorted(dictt.items(), key=lambda x: x[1], reverse=True)[0][0].split('_')[0]\n",
    "    print(most_liked_genre)\n",
    "    most_liked_genres_per_user[user_id] = most_liked_genre\n",
    "most_liked_genres_per_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_user_avg_genre_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_liked_genres_per_user_df = pd.DataFrame(list(most_liked_genres_per_user.items()), columns=['userId', 'most_liked_genre'])\n",
    "most_liked_genres_per_user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_user_genre_avg_df = pd.DataFrame(per_user_avg_genre_ratings)\n",
    "per_user_genre_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts_per_user = []\n",
    "per_user_genre_counts_copy = per_user_genre_counts.copy()\n",
    "for user_id in per_user_genre_counts_copy:\n",
    "    genre_counts = per_user_genre_counts_copy[user_id]\n",
    "    genre_counts['userId'] = user_id\n",
    "    genre_counts_per_user.append(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts_per_user_df = pd.DataFrame(genre_counts_per_user)\n",
    "genre_counts_per_user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_and_stat_merged_df = pd.merge(genre_counts_per_user_df, statistical_features_df, on='userId')\n",
    "counts_stat_and_avg_per_genre_merged_df = pd.merge(counts_and_stat_merged_df, per_user_genre_avg_df, on='userId')\n",
    "merged_with_most_rated_genre = pd.merge(counts_stat_and_avg_per_genre_merged_df, most_rated_genre_per_user_df, on='userId')\n",
    "final_df = pd.merge(merged_with_most_rated_genre, most_liked_genres_per_user_df, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_features_df = pd.get_dummies(final_df, columns=['most_rated_genre', 'most_liked_genre']) \n",
    "personal_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the personal features into disk for later use\n",
    "personal_features_df.to_csv('../data/dt-datasets/movielens/personal-features/personal_features_mlens_users_v1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "user_specific_features = pd.read_csv('../data/dt-datasets/movielens/personal-features/personal_features_mlens_users_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(no genres listed)_count',\n",
       " 'Action_count',\n",
       " 'Adventure_count',\n",
       " 'Animation_count',\n",
       " 'Children_count',\n",
       " 'Comedy_count',\n",
       " 'Crime_count',\n",
       " 'Documentary_count',\n",
       " 'Drama_count',\n",
       " 'Fantasy_count',\n",
       " 'Film-Noir_count',\n",
       " 'Horror_count',\n",
       " 'IMAX_count',\n",
       " 'Musical_count',\n",
       " 'Mystery_count',\n",
       " 'Romance_count',\n",
       " 'Sci-Fi_count',\n",
       " 'Thriller_count',\n",
       " 'War_count',\n",
       " 'Western_count',\n",
       " 'userId',\n",
       " 'highest_rating',\n",
       " 'lowest_rating',\n",
       " 'avg_rating',\n",
       " '(no genres listed)_avg_rating',\n",
       " 'Action_avg_rating',\n",
       " 'Adventure_avg_rating',\n",
       " 'Animation_avg_rating',\n",
       " 'Children_avg_rating',\n",
       " 'Comedy_avg_rating',\n",
       " 'Crime_avg_rating',\n",
       " 'Documentary_avg_rating',\n",
       " 'Drama_avg_rating',\n",
       " 'Fantasy_avg_rating',\n",
       " 'Film-Noir_avg_rating',\n",
       " 'Horror_avg_rating',\n",
       " 'IMAX_avg_rating',\n",
       " 'Musical_avg_rating',\n",
       " 'Mystery_avg_rating',\n",
       " 'Romance_avg_rating',\n",
       " 'Sci-Fi_avg_rating',\n",
       " 'Thriller_avg_rating',\n",
       " 'War_avg_rating',\n",
       " 'Western_avg_rating',\n",
       " 'most_rated_genre_Action',\n",
       " 'most_rated_genre_Adventure',\n",
       " 'most_rated_genre_Animation',\n",
       " 'most_rated_genre_Children',\n",
       " 'most_rated_genre_Comedy',\n",
       " 'most_rated_genre_Crime',\n",
       " 'most_rated_genre_Drama',\n",
       " 'most_rated_genre_Fantasy',\n",
       " 'most_rated_genre_Horror',\n",
       " 'most_rated_genre_Romance',\n",
       " 'most_rated_genre_Sci-Fi',\n",
       " 'most_rated_genre_Thriller',\n",
       " 'most_liked_genre_(no genres listed)',\n",
       " 'most_liked_genre_Action',\n",
       " 'most_liked_genre_Adventure',\n",
       " 'most_liked_genre_Animation',\n",
       " 'most_liked_genre_Children',\n",
       " 'most_liked_genre_Comedy',\n",
       " 'most_liked_genre_Crime',\n",
       " 'most_liked_genre_Documentary',\n",
       " 'most_liked_genre_Drama',\n",
       " 'most_liked_genre_Fantasy',\n",
       " 'most_liked_genre_Film-Noir',\n",
       " 'most_liked_genre_Horror',\n",
       " 'most_liked_genre_IMAX',\n",
       " 'most_liked_genre_Musical',\n",
       " 'most_liked_genre_Mystery',\n",
       " 'most_liked_genre_Romance',\n",
       " 'most_liked_genre_Sci-Fi',\n",
       " 'most_liked_genre_Thriller',\n",
       " 'most_liked_genre_War',\n",
       " 'most_liked_genre_Western']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_specific_features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user-specific features\n",
    "# per_genre_rating_count: how many movies per genre the user has rated\n",
    "# highest_rating_given: highest rating of the user for all movies\n",
    "# lowest_rating_given: lowest rating of the user for all movies\n",
    "# average_rating_given: overall average rating of the user for all movies\n",
    "# avg_rating_per_genre: average rating given per genre\n",
    "# most_rated_genre: based on the genre which has been rated by the most by the user\n",
    "# most_liked_genre: based on the highest rated genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1, 3)\n",
    "a.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1\n",
    "user_specific_features[user_specific_features['userId'] == user_id].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OHE of the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_features_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other features (will be refined later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the provided data\n",
    "data = {\n",
    "    'movieId': [1, 2, 3, 4, 5],\n",
    "    'title': ['The Shawshank Redemption', 'The Godfather', 'The Dark Knight', 'The Lord of the Rings: The Return of the King', 'The Matrix'],\n",
    "    'genres': ['Drama|Crime', 'Crime|Drama', 'Action|Crime|Thriller', 'Action|Adventure|Drama', 'Action|Sci-Fi'],\n",
    "    'userId': [1, 2, 1, 3, 3],\n",
    "    'rating': [5, 4, 5, 4, 3],\n",
    "    'timestamp': [1455359200, 1455359200, 1455359200, 1455359200, 1455359200]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a dictionary to store the top genres for each user\n",
    "top_genres = {}\n",
    "\n",
    "# Iterate over each user\n",
    "for userId in df['userId'].unique():\n",
    "    # Get the ratings for the current user\n",
    "    user_ratings = df[df['userId'] == userId]\n",
    "\n",
    "    # Create a dictionary to store the genres and their corresponding ratings\n",
    "    genre_ratings = {}\n",
    "\n",
    "    # Iterate over the ratings for the current user\n",
    "    for index, row in user_ratings.iterrows():\n",
    "        # Split the genres into a list\n",
    "        genres = row['genres'].split('|')\n",
    "\n",
    "        # Iterate over the genres\n",
    "        for genre in genres:\n",
    "            # Add the genre and its rating to the dictionary\n",
    "            if genre not in genre_ratings:\n",
    "                genre_ratings[genre] = row['rating']\n",
    "            else:\n",
    "                genre_ratings[genre] += row['rating']\n",
    "\n",
    "    # Create a list to store the top genres\n",
    "    top_genres_list = []\n",
    "\n",
    "    # Sort the genres by their average rating\n",
    "    genre_ratings_sorted = sorted(genre_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 5 genres\n",
    "    top_5_genres = genre_ratings_sorted[:5]\n",
    "\n",
    "    # Add the top 5 genres to the list\n",
    "    for genre, rating in top_5_genres:\n",
    "        top_genres_list.append(genre)\n",
    "\n",
    "    # Store the top 5 genres for the current user in the dictionary\n",
    "    top_genres[userId] = top_genres_list\n",
    "\n",
    "# Print the top genres for each user\n",
    "for userId, top_genres_list in top_genres.items():\n",
    "    print(f\"User {userId}: {top_genres_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the provided data\n",
    "data = {\n",
    "    'movieId': [1, 2, 3, 4, 5],\n",
    "    'title': ['The Shawshank Redemption', 'The Godfather', 'The Dark Knight', 'The Lord of the Rings: The Return of the King', 'The Matrix'],\n",
    "    'genres': ['Drama|Crime', 'Crime|Drama', 'Action|Crime|Thriller', 'Action|Adventure|Drama', 'Action|Sci-Fi'],\n",
    "    'userId': [1, 2, 1, 3, 3],\n",
    "    'rating': [5, 4, 5, 4, 3],\n",
    "    'timestamp': [1455359200, 1455359200, 1455359200, 1455359200, 1455359200]\n",
    "}\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "df = movies_and_ratings\n",
    "\n",
    "# Create a dictionary to store the genre consistency for each user\n",
    "genre_consistency = {}\n",
    "\n",
    "# Iterate over each user\n",
    "for userId in df['userId'].unique():\n",
    "    # Get the ratings for the current user\n",
    "    user_ratings = df[df['userId'] == userId]\n",
    "\n",
    "    # Create a dictionary to store the genres and their corresponding frequency\n",
    "    genre_counts = {}\n",
    "\n",
    "    # Iterate over the ratings for the current user\n",
    "    for index, row in user_ratings.iterrows():\n",
    "        # Split the genres into a list\n",
    "        genres = row['genres'].split('|')\n",
    "\n",
    "        # Iterate over the genres\n",
    "        for genre in genres:\n",
    "            # Add the genre and its frequency to the dictionary\n",
    "            if genre not in genre_counts:\n",
    "                genre_counts[genre] = 1\n",
    "            else:\n",
    "                genre_counts[genre] += 1\n",
    "\n",
    "    # Calculate the genre consistency for the current user\n",
    "    genre_consistency_score = 0\n",
    "    for genre, count in genre_counts.items():\n",
    "        # Calculate the proportion of ratings for the genre\n",
    "        proportion = count / len(user_ratings)\n",
    "\n",
    "        # Calculate the squared deviation from the mean\n",
    "        deviation = proportion - 0.25\n",
    "        squared_deviation = deviation ** 2\n",
    "\n",
    "        # Add the squared deviation to the score\n",
    "        genre_consistency_score += squared_deviation\n",
    "\n",
    "    # Store the genre consistency score for the current user in the dictionary\n",
    "    genre_consistency[userId] = genre_consistency_score\n",
    "\n",
    "# Print the genre consistency for each user\n",
    "for userId, consistency_score in genre_consistency.items():\n",
    "    print(f\"User {userId}: {consistency_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0.5, 5, 0.5)\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(genre_consistency.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_and_ratings[movies_and_ratings['userId'] == 149][['genres', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# # Example list of movies with genres\n",
    "# movies = [\n",
    "#     \"Movie1\", \"Movie2\", \"Movie3\", \"Movie4\",\n",
    "#     \"Movie5\", \"Movie6\", \"Movie7\", \"Movie8\",\n",
    "# ]\n",
    "\n",
    "# genres = [\n",
    "#     \"Animation|Children|Drama\",\n",
    "#     \"Action|Adventure|Fantasy\",\n",
    "#     \"Comedy|Romance\",\n",
    "#     \"Drama\",\n",
    "#     \"Comedy|Drama|Romance\",\n",
    "#     \"Action|Adventure|Fantasy\",\n",
    "#     \"Drama\",\n",
    "#     \"Animation|Children|Fantasy\",\n",
    "# ]\n",
    "\n",
    "# # Split genres into lists\n",
    "# genre_lists = [genre.split('|') for genre in genres]\n",
    "\n",
    "# # Use MultiLabelBinarizer to one-hot encode genres\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# genre_matrix = mlb.fit_transform(genre_lists)\n",
    "\n",
    "# # Apply K-Means clustering\n",
    "# num_clusters = 3  # You can choose the number of clusters based on your requirements\n",
    "# kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "# cluster_labels = kmeans.fit_predict(genre_matrix)\n",
    "\n",
    "# # Assign movies to clusters\n",
    "# movie_clusters = {}\n",
    "# for movie, cluster_label in zip(movies, cluster_labels):\n",
    "#     if cluster_label not in movie_clusters:\n",
    "#         movie_clusters[cluster_label] = []\n",
    "#     movie_clusters[cluster_label].append(movie)\n",
    "\n",
    "# # Print the clusters\n",
    "# for cluster, movies_in_cluster in movie_clusters.items():\n",
    "#     print(f\"Cluster {cluster + 1}: {movies_in_cluster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Apply PCA to reduce dimensionality to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# reduced_features = pca.fit_transform(genre_matrix)\n",
    "\n",
    "# # Create a scatter plot of the clusters\n",
    "# plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=cluster_labels)\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.title('Cluster Visualization using PCA')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Apply t-SNE to reduce dimensionality to 2D\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# reduced_features = tsne.fit_transform(genre_matrix)\n",
    "\n",
    "# # Create a scatter plot of the clusters\n",
    "# plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=cluster_labels)\n",
    "# plt.xlabel('t-SNE Component 1')\n",
    "# plt.ylabel('t-SNE Component 2')\n",
    "# plt.title('Cluster Visualization using t-SNE')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Fit K-Means to obtain cluster centroids\n",
    "# kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "# kmeans.fit(genre_matrix)\n",
    "\n",
    "# # Plot cluster centroids\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for i, cluster_center in enumerate(kmeans.cluster_centers_):\n",
    "#     plt.plot(cluster_center, label=f'Cluster {i + 1}')\n",
    "# plt.xlabel('Genre Feature')\n",
    "# plt.ylabel('Feature Value')\n",
    "# plt.title('Cluster Centroids')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# # Sample data\n",
    "# data = {\n",
    "#     'UserID': [1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6],\n",
    "#     'MovieID': [101, 102, 103, 104, 105, 106, 101, 103, 106, 102, 104],\n",
    "#     'MovieName': ['Movie1', 'Movie2', 'Movie3', 'Movie4', 'Movie5', 'Movie6', 'Movie1', 'Movie3', 'Movie6', 'Movie2', 'Movie4'],\n",
    "#     'MovieGenre': ['Action|Adventure|Fantasy', 'Action|Drama', 'Action|Adventure|Fantasy', 'Drama', 'Comedy|Romance', 'Action|Adventure|Fantasy', 'Action|Adventure|Fantasy', 'Comedy|Romance', 'Action|Adventure|Fantasy', 'Action|Drama', 'Drama'],\n",
    "#     'Rating': [4.5, 3.0, 4.0, 3.5, 4.5, 3.0, 3.5, 4.0, 3.0, 2.5, 3.5]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Split genres into lists\n",
    "# df['MovieGenre'] = df['MovieGenre'].apply(lambda x: x.split('|'))\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use MultiLabelBinarizer to one-hot encode genres\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# genre_matrix = mlb.fit_transform(df['MovieGenre'])\n",
    "# genre_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a user-item matrix with user ratings\n",
    "# user_item_matrix = pd.pivot_table(df, index='UserID', columns='MovieName', values='Rating')\n",
    "# # Handle missing values in the user-item matrix\n",
    "# user_item_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply K-Means clustering to the user-item matrix\n",
    "# num_clusters = 2  # Adjust based on your preference\n",
    "# kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "# cluster_labels = kmeans.fit_predict(user_item_matrix)\n",
    "\n",
    "# # Assign labels to user clusters based on interpretation\n",
    "# user_clusters = {}\n",
    "# for user, cluster_label in zip(user_item_matrix.index, cluster_labels):\n",
    "#     if cluster_label not in user_clusters:\n",
    "#         user_clusters[cluster_label] = []\n",
    "#     user_clusters[cluster_label].append(user)\n",
    "\n",
    "# # Print user clusters\n",
    "# for cluster, users_in_cluster in user_clusters.items():\n",
    "#     print(f\"Cluster {cluster + 1}: {users_in_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reduce dimensionality with PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# reduced_features = pca.fit_transform(user_item_matrix)\n",
    "\n",
    "# # # Assign labels to user clusters based on interpretation\n",
    "# # user_clusters = {}\n",
    "# # for user, cluster_label in zip(user_item_matrix.index, cluster_labels):\n",
    "# #     if cluster_label not in user_clusters:\n",
    "# #         user_clusters[cluster_label] = []\n",
    "# #     user_clusters[cluster_label].append(user)\n",
    "\n",
    "# # # Create a scatter plot of the clusters\n",
    "# # plt.figure(figsize=(8, 6))\n",
    "# # for cluster, users_in_cluster in user_clusters.items():\n",
    "# #     x = reduced_features[users_in_cluster, 0]\n",
    "# #     y = reduced_features[users_in_cluster, 1]\n",
    "# #     plt.scatter(x, y, label=f'Cluster {cluster + 1}')\n",
    "# # plt.xlabel('PCA Component 1')\n",
    "# # plt.ylabel('PCA Component 2')\n",
    "# # plt.title('User Clusters Visualization')\n",
    "# # plt.legend()\n",
    "# # plt.show()\n",
    "\n",
    "# # Create a scatter plot of the clusters\n",
    "# plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=cluster_labels)\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.title('Cluster Visualization using PCA')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# # Sample data with multiple users and movies\n",
    "# data = {\n",
    "#     'UserID': [1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6],\n",
    "#     'MovieID': [101, 102, 103, 104, 105, 106, 101, 103, 106, 102, 104],\n",
    "#     'MovieName': ['Movie1', 'Movie2', 'Movie3', 'Movie4', 'Movie5', 'Movie6', 'Movie1', 'Movie3', 'Movie6', 'Movie2', 'Movie4'],\n",
    "#     'MovieGenre': ['Action|Adventure|Fantasy', 'Action|Drama', 'Action|Adventure|Fantasy', 'Drama', 'Comedy|Romance', 'Action|Adventure|Fantasy', 'Action|Adventure|Fantasy', 'Comedy|Romance', 'Action|Adventure|Fantasy', 'Action|Drama', 'Drama'],\n",
    "#     'Rating': [4.5, 3.0, 4.0, 3.5, 4.5, 3.0, 3.5, 4.0, 3.0, 2.5, 3.5]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Split genres into lists\n",
    "# df['MovieGenre'] = df['MovieGenre'].apply(lambda x: x.split('|'))\n",
    "\n",
    "# # Use MultiLabelBinarizer to one-hot encode genres\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# genre_matrix = mlb.fit_transform(df['MovieGenre'])\n",
    "# genre_matrix.shape\n",
    "\n",
    "# # Create a user-item matrix with user ratings\n",
    "# user_item_matrix = pd.pivot_table(df, index='UserID', columns='MovieName', values='Rating')\n",
    "\n",
    "# # Handle missing values in the user-item matrix\n",
    "# user_item_matrix.fillna(0, inplace=True)\n",
    "# genre_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate user preferences for genres\n",
    "# user_preferences = {}\n",
    "# for user in user_item_matrix.index:\n",
    "#     user_ratings = user_item_matrix.loc[user].values\n",
    "#     print(user_ratings)\n",
    "#     genre_ratings = np.dot(user_ratings, genre_matrix.T)\n",
    "#     print(genre_ratings)\n",
    "#     total_genre_movies = np.sum(genre_matrix, axis=0)\n",
    "#     user_genre_preferences = genre_ratings / (total_genre_movies + 1e-9)  # Add a small epsilon to avoid division by zero\n",
    "#     user_preferences[user] = user_genre_preferences\n",
    "\n",
    "# # Define a threshold (75% of movies with ratings >= 4) for genre lover\n",
    "# threshold = 0.75\n",
    "\n",
    "# # Create columns for each genre lover\n",
    "# for genre_index, genre_name in enumerate(mlb.classes_):\n",
    "#     column_name = genre_name.lower() + '_lover'\n",
    "#     df[column_name] = [user_preferences[user][genre_index] >= threshold for user in df['UserID']]\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Load BERT model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# all_genres = np.unique(np.concatenate(movies_and_ratings['genres'].apply(lambda g: g.split(\"|\")).tolist()))\n",
    "# print(all_genres)\n",
    "\n",
    "\n",
    "\n",
    "# # Define a list of words you want to cluster\n",
    "# # word_list = [\"apple\", \"banana\", \"orange\", \"car\", \"bus\", \"train\", \"elephant\", \"lion\", \"tiger\"]\n",
    "# word_list = all_genres\n",
    "\n",
    "# # Encode the words and get BERT embeddings\n",
    "# word_embeddings = []\n",
    "# for word in word_list:\n",
    "#     inputs = tokenizer(word, return_tensors='pt')\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     word_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "#     word_embeddings.append(word_embedding)\n",
    "\n",
    "# # Convert the list of embeddings into a NumPy array\n",
    "# word_embeddings = np.array(word_embeddings)\n",
    "\n",
    "# # Apply PCA for dimensionality reduction (optional)\n",
    "# pca = PCA(n_components=2)\n",
    "# word_embeddings_pca = pca.fit_transform(word_embeddings)\n",
    "\n",
    "# # Cluster the word embeddings using K-Means\n",
    "# num_clusters = 5  # Adjust this based on your needs\n",
    "# kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "# clusters = kmeans.fit_predict(word_embeddings_pca)\n",
    "\n",
    "# # Plot the clustered words\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "# for i in range(len(word_list)):\n",
    "#     plt.scatter(word_embeddings_pca[i, 0], word_embeddings_pca[i, 1], c=colors[clusters[i]], label=word_list[i])\n",
    "\n",
    "# # Add labels to data points\n",
    "# for i in range(len(word_list)):\n",
    "#     plt.annotate(word_list[i], (word_embeddings_pca[i, 0], word_embeddings_pca[i, 1]))\n",
    "\n",
    "# plt.title('Word Clustering with BERT Embeddings')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt-gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
