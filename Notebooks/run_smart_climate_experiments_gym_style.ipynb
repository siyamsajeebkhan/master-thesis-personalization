{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/q621464/Desktop/Thesis/code/decision-transformer-thesis\")\n",
    "sys.path.append(\"/home/q621464/Desktop/Thesis/code/decision-transformer-thesis/smart-climate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from decision_transformer.evaluation.evaluate_episodes import evaluate_episode, evaluate_episode_rtg\n",
    "from decision_transformer.models.decision_transformer import DecisionTransformer\n",
    "from decision_transformer.models.mlp_bc import MLPBCModel\n",
    "from decision_transformer.training.act_trainer import ActTrainer\n",
    "from decision_transformer.training.seq_trainer import SequenceTrainer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_cumsum(x, gamma):\n",
    "    discount_cumsum = np.zeros_like(x)\n",
    "    discount_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        discount_cumsum[t] = x[t] + gamma * discount_cumsum[t+1]\n",
    "    return discount_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, seed=123, context_length=30, epochs=5, model_type='reward_conditioned', num_steps=500000, num_buffers=50, env='SmartClimate', batch_size=128, log_to_wandb=False, trajectories_per_buffer=10, train_data_dir='../atari/data-for-dt/smart-climate-train-trajectories-v2.pkl', val_data_dir='../atari/data-for-dt/smart-climate-val-trajectories-v2.pkl', test_data_dir='../atari/data-for-dt/smart-climate-test-trajectories-v2.pkl') -> None:\n",
    "        self.seed = seed\n",
    "        self.context_length = context_length\n",
    "        self.epochs = epochs\n",
    "        self.model_type = model_type\n",
    "        self.num_steps =num_steps\n",
    "        self.num_buffers = num_buffers\n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.log_to_wandb = log_to_wandb\n",
    "        self.trajectories_per_buffer = trajectories_per_buffer\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.val_data_dir = val_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.dim_reductor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "        exp_prefix,\n",
    "        variant,\n",
    "):\n",
    "    device = variant.get('device', 'cuda')\n",
    "    log_to_wandb = variant.get('log_to_wandb', False)\n",
    "\n",
    "    env_name, dataset = variant['env'], variant['dataset']\n",
    "    model_type = variant['model_type']\n",
    "    group_name = f'{exp_prefix}-{env_name}-{dataset}'\n",
    "    exp_prefix = f'{group_name}-{random.randint(int(1e5), int(1e6) - 1)}'\n",
    "\n",
    "    if env_name == 'hopper':\n",
    "        env = gym.make('Hopper-v3')\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [3600, 1800]  # evaluation conditioning targets\n",
    "        scale = 1000.  # normalization for rewards/returns\n",
    "    elif env_name == 'halfcheetah':\n",
    "        env = gym.make('HalfCheetah-v3')\n",
    "        max_ep_len = 100\n",
    "        env_targets = [12000, 6000]\n",
    "        scale = 1000.\n",
    "    elif env_name == 'walker2d':\n",
    "        env = gym.make('Walker2d-v3')\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [5000, 2500]\n",
    "        scale = 1000.\n",
    "    elif env_name == 'reacher2d':\n",
    "        from decision_transformer.envs.reacher_2d import Reacher2dEnv\n",
    "        env = Reacher2dEnv()\n",
    "        max_ep_len = 100\n",
    "        env_targets = [76, 40]\n",
    "        scale = 10.\n",
    "    elif env_name == 'smartclimate':\n",
    "        from decision_transformer.envs.smart_climate_env import SmartClimateEnv\n",
    "        env = SmartClimateEnv()\n",
    "        max_ep_len = 100\n",
    "        env_targets = [100, 70]\n",
    "        scale = 1\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if model_type == 'bc':\n",
    "        env_targets = env_targets[:1]  # since BC ignores target, no need for different evaluations\n",
    "\n",
    "    # state_dim = env.observation_space.shape[0]\n",
    "    # act_dim = env.action_space.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "    # load dataset\n",
    "    # dataset_path = f'data/{env_name}-{dataset}-v2.pkl'\n",
    "    dataset_path = f\"../smart-climate/data/smart-climate/smart-climate-train-trajectories-v5.pkl\"\n",
    "    with open(dataset_path, 'rb') as f:\n",
    "        trajectories = pickle.load(f)[0:500]\n",
    "\n",
    "    # save all path information into separate lists\n",
    "    mode = variant.get('mode', 'normal')\n",
    "    states, traj_lens, returns = [], [], []\n",
    "    for path in trajectories:\n",
    "        if mode == 'delayed':  # delayed: all rewards moved to end of trajectory\n",
    "            path['rewards'][-1] = path['rewards'].sum()\n",
    "            path['rewards'][:-1] = 0.\n",
    "        states.append(path['observations'])\n",
    "        traj_lens.append(len(path['observations']))\n",
    "        returns.append(path['rewards'].sum())\n",
    "    traj_lens, returns = np.array(traj_lens), np.array(returns)\n",
    "    \n",
    "    state_dim = states[0].shape[1]\n",
    "    act_dim = 1\n",
    "\n",
    "    # used for input normalization\n",
    "    states = np.concatenate(states, axis=0)\n",
    "    state_mean, state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "    num_timesteps = sum(traj_lens)\n",
    "\n",
    "    print('=' * 50)\n",
    "    print(f'Starting new experiment: {env_name} {dataset}')\n",
    "    print(f'{len(traj_lens)} trajectories, {num_timesteps} timesteps found')\n",
    "    print(f'Average return: {np.mean(returns):.2f}, std: {np.std(returns):.2f}')\n",
    "    print(f'Max return: {np.max(returns):.2f}, min: {np.min(returns):.2f}')\n",
    "    print('=' * 50)\n",
    "\n",
    "    K = variant['K']\n",
    "    batch_size = variant['batch_size']\n",
    "    num_eval_episodes = variant['num_eval_episodes']\n",
    "    pct_traj = variant.get('pct_traj', 1.)\n",
    "\n",
    "    # only train on top pct_traj trajectories (for %BC experiment)\n",
    "    num_timesteps = max(int(pct_traj*num_timesteps), 1)\n",
    "    sorted_inds = np.argsort(returns)  # lowest to highest\n",
    "    num_trajectories = 1\n",
    "    timesteps = traj_lens[sorted_inds[-1]]\n",
    "    ind = len(trajectories) - 2\n",
    "    while ind >= 0 and timesteps + traj_lens[sorted_inds[ind]] <= num_timesteps:\n",
    "        timesteps += traj_lens[sorted_inds[ind]]\n",
    "        num_trajectories += 1\n",
    "        ind -= 1\n",
    "    sorted_inds = sorted_inds[-num_trajectories:]\n",
    "\n",
    "    # used to reweight sampling so we sample according to timesteps instead of trajectories\n",
    "    p_sample = traj_lens[sorted_inds] / sum(traj_lens[sorted_inds])\n",
    "\n",
    "    def get_batch(batch_size=256, max_len=K):\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(num_trajectories),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            traj = trajectories[int(sorted_inds[batch_inds[i]])]\n",
    "            si = random.randint(0, traj['rewards'].shape[0] - 1)\n",
    "            \n",
    "            # get sequences from dataset\n",
    "            s.append(traj['observations'][si:si + max_len].reshape(1, -1, state_dim))\n",
    "            a.append(traj['actions'][si:si + max_len].reshape(1, -1, act_dim))\n",
    "            r.append(traj['rewards'][si:si + max_len].reshape(1, -1, 1))\n",
    "            \n",
    "            # print(f\"reward shape: {r[-1].shape}\")\n",
    "            # print(f\"size of s: {s[-1].shape}\")\n",
    "            if 'terminals' in traj:\n",
    "                d.append(traj['terminals'][si:si + max_len].reshape(1, -1))\n",
    "            else:\n",
    "                d.append(traj['dones'][si:si + max_len].reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= max_ep_len] = max_ep_len-1  # padding cutoff\n",
    "            rtg.append(discount_cumsum(traj['rewards'][si:], gamma=1.)[:s[-1].shape[1] + 1].reshape(1, -1, 1))\n",
    "            if rtg[-1].shape[1] <= s[-1].shape[1]:\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, max_len - tlen, state_dim)), s[-1]], axis=1)\n",
    "            s[-1] = (s[-1] - state_mean) / state_std\n",
    "            a[-1] = np.concatenate([np.ones((1, max_len - tlen, act_dim)) * -10., a[-1]], axis=1)\n",
    "            r[-1] = np.concatenate([np.zeros((1, max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, max_len - tlen, 1)), rtg[-1]], axis=1) / scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).to(dtype=torch.float32, device=device)\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).to(dtype=torch.float32, device=device)\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).to(dtype=torch.float32, device=device)\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0)).to(dtype=torch.long, device=device)\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).to(dtype=torch.float32, device=device)\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).to(dtype=torch.long, device=device)\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).to(device=device)\n",
    "\n",
    "\n",
    "        return s, a, r, d, rtg, timesteps, mask\n",
    "    def eval_episodes(target_rew):\n",
    "        def fn(model):\n",
    "            returns, lengths = [], []\n",
    "            for _ in tqdm(range(num_eval_episodes), disable=False):\n",
    "                with torch.no_grad():\n",
    "                    if model_type == 'dt':\n",
    "                        ret, length = evaluate_episode_rtg(\n",
    "                            env,\n",
    "                            state_dim,\n",
    "                            act_dim,\n",
    "                            model,\n",
    "                            max_ep_len=max_ep_len,\n",
    "                            scale=scale,\n",
    "                            target_return=target_rew/scale,\n",
    "                            mode=mode,\n",
    "                            state_mean=state_mean,\n",
    "                            state_std=state_std,\n",
    "                            device=device,\n",
    "                        )\n",
    "                    else:\n",
    "                        ret, length = evaluate_episode(\n",
    "                            env,\n",
    "                            state_dim,\n",
    "                            act_dim,\n",
    "                            model,\n",
    "                            max_ep_len=max_ep_len,\n",
    "                            target_return=target_rew/scale,\n",
    "                            mode=mode,\n",
    "                            state_mean=state_mean,\n",
    "                            state_std=state_std,\n",
    "                            device=device,\n",
    "                        )\n",
    "                returns.append(ret)\n",
    "                lengths.append(length)\n",
    "            return {\n",
    "                f'target_{target_rew}_return_mean': np.mean(returns),\n",
    "                f'target_{target_rew}_return_std': np.std(returns),\n",
    "                f'target_{target_rew}_length_mean': np.mean(lengths),\n",
    "                f'target_{target_rew}_length_std': np.std(lengths),\n",
    "            }\n",
    "        return fn\n",
    "\n",
    "    if model_type == 'dt':\n",
    "        model = DecisionTransformer(\n",
    "            state_dim=state_dim,\n",
    "            act_dim=act_dim,\n",
    "            max_length=K,\n",
    "            vocab_size=25,\n",
    "            max_ep_len=max_ep_len,\n",
    "            hidden_size=variant['embed_dim'],\n",
    "            n_layer=variant['n_layer'],\n",
    "            n_head=variant['n_head'],\n",
    "            n_inner=4*variant['embed_dim'],\n",
    "            activation_function=variant['activation_function'],\n",
    "            n_positions=1024,\n",
    "            resid_pdrop=variant['dropout'],\n",
    "            attn_pdrop=variant['dropout'],\n",
    "        )\n",
    "    elif model_type == 'bc':\n",
    "        model = MLPBCModel(\n",
    "            state_dim=state_dim,\n",
    "            act_dim=act_dim,\n",
    "            max_length=K,\n",
    "            hidden_size=variant['embed_dim'],\n",
    "            n_layer=variant['n_layer'],\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    warmup_steps = variant['warmup_steps']\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=variant['learning_rate'],\n",
    "        weight_decay=variant['weight_decay'],\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lambda steps: min((steps+1)/warmup_steps, 1)\n",
    "    )\n",
    "\n",
    "    if model_type == 'dt':\n",
    "        trainer = SequenceTrainer(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            batch_size=batch_size,\n",
    "            get_batch=get_batch,\n",
    "            scheduler=scheduler,\n",
    "            loss_fn=lambda s_hat, a_hat, r_hat, s, a, r: torch.mean((a_hat - a)**2),\n",
    "            eval_fns=[eval_episodes(tar) for tar in env_targets],\n",
    "        )\n",
    "    elif model_type == 'bc':\n",
    "        trainer = ActTrainer(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            batch_size=batch_size,\n",
    "            get_batch=get_batch,\n",
    "            scheduler=scheduler,\n",
    "            loss_fn=lambda s_hat, a_hat, r_hat, s, a, r: torch.mean((a_hat - a)**2),\n",
    "            eval_fns=[eval_episodes(tar) for tar in env_targets],\n",
    "        )\n",
    "\n",
    "    if log_to_wandb:\n",
    "        wandb.init(\n",
    "            name=exp_prefix,\n",
    "            group=group_name,\n",
    "            project='decision-transformer',\n",
    "            config=variant\n",
    "        )\n",
    "        # wandb.watch(model)  # wandb has some bug\n",
    "\n",
    "    for iter in range(variant['max_iters']):\n",
    "        outputs = trainer.train_iteration(num_steps=variant['num_steps_per_iter'], iter_num=iter+1, print_logs=True)\n",
    "        if log_to_wandb:\n",
    "            wandb.log(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--env', type=str, default='smartclimate')\n",
    "parser.add_argument('--dataset', type=str, default='medium')  # medium, medium-replay, medium-expert, expert\n",
    "parser.add_argument('--mode', type=str, default='normal')  # normal for standard setting, delayed for sparse\n",
    "parser.add_argument('--K', type=int, default=20)\n",
    "parser.add_argument('--pct_traj', type=float, default=1.)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--model_type', type=str, default='dt')  # dt for decision transformer, bc for behavior cloning\n",
    "parser.add_argument('--embed_dim', type=int, default=128)\n",
    "parser.add_argument('--n_layer', type=int, default=3)\n",
    "parser.add_argument('--n_head', type=int, default=1)\n",
    "parser.add_argument('--activation_function', type=str, default='relu')\n",
    "parser.add_argument('--dropout', type=float, default=0.1)\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=1e-4)\n",
    "parser.add_argument('--weight_decay', '-wd', type=float, default=1e-4)\n",
    "parser.add_argument('--warmup_steps', type=int, default=10000)\n",
    "parser.add_argument('--num_eval_episodes', type=int, default=100)\n",
    "parser.add_argument('--max_iters', type=int, default=10)\n",
    "parser.add_argument('--num_steps_per_iter', type=int, default=100)\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "parser.add_argument('--log_to_wandb', '-w', type=bool, default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment('gym-experiment', variant=vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"../smart-climate/data/smart-climate/smart-climate-train-trajectories-v5.pkl\"\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    trajectories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [traj['actions'] for traj in trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn(64, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "probs = F.softmax(logits, dim=0)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DecisionTransformerModel\n",
    "\n",
    "model_name = \"edbeeching/decision-transformer-gym-hopper-expert\"\n",
    "model = DecisionTransformerModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(actions).min(), np.concatenate(actions).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DecisionTransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_embeddings = torch.randn(64, 20, 128)\n",
    "returns_embeddings = torch.randn(64, 20, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "seq_length = 20\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_inputs = torch.stack(\n",
    "    (returns_embeddings, state_embeddings), dim=1\n",
    ").permute(0, 2, 1, 3).reshape(batch_size, 2*seq_length, hidden_size)\n",
    "stacked_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones((batch_size, seq_length), dtype=torch.long)\n",
    "attention_mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_attention_mask = torch.stack(\n",
    "    (attention_mask, attention_mask), dim=1\n",
    ").permute(0, 2, 1).reshape(batch_size, 2*seq_length)\n",
    "stacked_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64, 2, 20, 128)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.randn(10, 5)\n",
    "states.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sample data\n",
    "data = {'visit_id': [1, 1, 2, 2],\n",
    "        'timestamp': ['2022-12-03 10:50:20', '2022-12-03 10:58:00', '2022-12-03 11:05:17', '2022-12-03 11:20:40'],\n",
    "        'event': ['Event A', 'Event B', 'Event C', 'Event D']}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort the dataframe by visit_id and timestamp\n",
    "df = df.sort_values(['visit_id', 'timestamp'])\n",
    "\n",
    "# Initialize an empty list to store new rows\n",
    "new_rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate new timestamps at 10-second intervals\n",
    "def generate_new_timestamps(row, next_row):\n",
    "    time_diff = (next_row['timestamp'] - row['timestamp']).total_seconds()\n",
    "    num_intervals = int(time_diff / 10)\n",
    "    new_timestamps = [row['timestamp'] + timedelta(seconds=60 * i) for i in range(1, num_intervals)]\n",
    "    \n",
    "    # Ensure new timestamps do not exceed the next event's timestamp\n",
    "    new_timestamps = [ts for ts in new_timestamps if ts < next_row['timestamp']]\n",
    "    return new_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through groups (each group is a visit)\n",
    "for _, group in df.groupby('visit_id'):\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # Iterate through the rows within the group to fill gaps\n",
    "    for i in range(len(group) - 1):\n",
    "        current_row = group.iloc[i]\n",
    "        next_row = group.iloc[i + 1]\n",
    "        \n",
    "        new_rows.append(current_row.to_dict())\n",
    "        \n",
    "        # Generate new timestamps at 10-second intervals\n",
    "        new_timestamps = generate_new_timestamps(current_row, next_row)\n",
    "        for new_timestamp in new_timestamps:\n",
    "            new_rows.append({'visit_id': current_row['visit_id'], 'timestamp': new_timestamp, 'event': current_row['event']})\n",
    "    \n",
    "    # Add the last row in the group\n",
    "    new_rows.append(group.iloc[-1].to_dict())\n",
    "\n",
    "# Create a new dataframe with the filled gaps\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# print(new_df)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[new_df['visit_id'] == 1].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-20 06:30:37.899</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-20 06:31:07.899</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-20 06:31:37.899</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-20 06:32:07.899</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-20 06:33:05.626</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:40:05.626</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:40:35.626</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:41:05.626</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:41:35.626</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:42:05.626</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:42:35.626</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-20 06:43:05.626</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    visit_id               timestamp  feature1  feature2\n",
       "0          1 2021-05-20 06:30:37.899        10         5\n",
       "1          1 2021-05-20 06:31:07.899        10         5\n",
       "2          1 2021-05-20 06:31:37.899        10         5\n",
       "3          1 2021-05-20 06:32:07.899        10         5\n",
       "4          1 2021-05-20 06:33:05.626        20         8\n",
       "5          2 2021-05-20 06:40:05.626        15         6\n",
       "6          2 2021-05-20 06:40:35.626        15         6\n",
       "7          2 2021-05-20 06:41:05.626        15         6\n",
       "8          2 2021-05-20 06:41:35.626        15         6\n",
       "9          2 2021-05-20 06:42:05.626        15         6\n",
       "10         2 2021-05-20 06:42:35.626        15         6\n",
       "11         2 2021-05-20 06:43:05.626        30        12"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Altogether\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'visit_id': [1, 1, 2, 2],\n",
    "    'timestamp': ['2021-05-20 06:30:37.899', '2021-05-20 06:33:05.626', '2021-05-20 06:40:05.626', '2021-05-20 06:43:05.626'],\n",
    "    'feature1': [10, 20, 15, 30],\n",
    "    'feature2': [5, 8, 6, 12],\n",
    "    # ... add other features ...\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])  # Convert to datetime object\n",
    "\n",
    "# Sort the dataframe by visit_id and timestamp\n",
    "df = df.sort_values(['visit_id', 'timestamp'])\n",
    "\n",
    "# Initialize an empty list to store new rows\n",
    "new_rows = []\n",
    "\n",
    "# Function to calculate new timestamps at 10-second intervals\n",
    "def generate_new_timestamps(row, next_row):\n",
    "    time_diff = (next_row['timestamp'] - row['timestamp']).total_seconds()\n",
    "    num_intervals = int(time_diff / 30)\n",
    "    new_timestamps = [row['timestamp'] + timedelta(seconds=30 * i) for i in range(1, num_intervals)]\n",
    "    \n",
    "    # Ensure new timestamps do not exceed the next event's timestamp\n",
    "    new_timestamps = [ts for ts in new_timestamps if ts < next_row['timestamp']]\n",
    "    return new_timestamps\n",
    "\n",
    "# Iterate through groups (each group is a visit)\n",
    "for _, group in df.groupby('visit_id'):\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # Iterate through the rows within the group to fill gaps\n",
    "    for i in range(len(group) - 1):\n",
    "        current_row = group.iloc[i]\n",
    "        next_row = group.iloc[i + 1]\n",
    "        \n",
    "        new_rows.append(current_row.to_dict())\n",
    "        \n",
    "        # Generate new timestamps at 10-second intervals\n",
    "        new_timestamps = generate_new_timestamps(current_row, next_row)\n",
    "        for new_timestamp in new_timestamps:\n",
    "            new_row = current_row.copy()\n",
    "            new_row['timestamp'] = new_timestamp\n",
    "            new_rows.append(new_row.to_dict())\n",
    "    \n",
    "    # Add the last row in the group\n",
    "    new_rows.append(group.iloc[-1].to_dict())\n",
    "\n",
    "# Create a new dataframe with the filled gaps\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# print(new_df)\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1      30.000\n",
       "2      30.000\n",
       "3      30.000\n",
       "4      57.727\n",
       "5     420.000\n",
       "6      30.000\n",
       "7      30.000\n",
       "8      30.000\n",
       "9      30.000\n",
       "10     30.000\n",
       "11     30.000\n",
       "Name: timestamp, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['timestamp'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = results['epoch_losses']\n",
    "val_losses = results['val_losses']\n",
    "predicted_actions = results['predicted _actions']\n",
    "target_actions = results['target_actions']\n",
    "train_epoch_accuracies = results['train_accuracies']\n",
    "val_accuracies = results['val_accuracies']\n",
    "returns = results['epoch_returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title(f\"train and val loss for {len(train_dataset)} train and {len(val_dataset)} datapoints with batch size {args.batch_size}\")\n",
    "# plt.show()\n",
    "# plt.savefig(f'Figures/train_and_val_loss_for_{len(train_dataset)}_datapoints.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_epoch_accuracies, label='train_acc')\n",
    "plt.plot(val_accuracies, label='val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title(f\"train and val acc for {len(train_dataset)} train and {len(val_dataset)} datapoints\")\n",
    "# plt.show()\n",
    "# plt.savefig(f'Figures/train_and_val_loss_for_{len(train_dataset)}_datapoints.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atari.mingpt.envs.smart_climate_env import CustomActionSpace\n",
    "action_map = CustomActionSpace().actions_map\n",
    "\n",
    "train_actions_str = [str(action_map[action]) for action in actions]\n",
    "predicted_actions_str = [str(action) for action in predicted_actions]\n",
    "target_actions_str = [str(action) for action in target_actions]\n",
    "val_actions_str = [str(action_map[action]) for action in actions_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actions_unique, counts = np.unique(train_actions_str, return_counts=True)\n",
    "train_action_count_dict = dict(zip(train_actions_unique, counts))\n",
    "\n",
    "target_actions_unique, counts = np.unique(target_actions_str, return_counts=True)\n",
    "target_action_count_dict = dict(zip(target_actions_unique, counts))\n",
    "\n",
    "predicted_actions_unique, counts = np.unique(predicted_actions_str, return_counts=True)\n",
    "predicted_action_count_dict = dict(zip(predicted_actions_unique, counts))\n",
    "\n",
    "val_actions_unique, counts = np.unique(val_actions_str, return_counts=True)\n",
    "val_action_count_dict = dict(zip(val_actions_unique, counts))\n",
    "\n",
    "for action in np.arange(16.0, 28.5, 0.5):\n",
    "    if str(action) not in predicted_action_count_dict.keys():\n",
    "        predicted_action_count_dict[str(action)] = 0\n",
    "    if str(action) not in train_action_count_dict.keys():\n",
    "        train_action_count_dict[str(action)] = 0\n",
    "    if str(action) not in target_action_count_dict.keys():\n",
    "        target_action_count_dict[str(action)] = 0\n",
    "    if str(action) not in val_action_count_dict.keys():\n",
    "        val_action_count_dict[str(action)] = 0\n",
    "\n",
    "sorted_keys = sorted(predicted_action_count_dict)\n",
    "predicted_action_count_dict = {key: predicted_action_count_dict[key] for key in sorted_keys}\n",
    "train_action_count_dict = {key: train_action_count_dict[key] for key in sorted_keys}\n",
    "target_action_count_dict = {key: target_action_count_dict[key] for key in sorted_keys}\n",
    "val_action_count_dict = {key: val_action_count_dict[key] for key in sorted_keys}\n",
    "\n",
    "sorted(train_action_count_dict.keys()) == sorted(predicted_action_count_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(target_actions_str, predicted_actions_str)\n",
    "print(f\"Evaluation Accuracy: {accuracy * 100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "macro_f1 = f1_score(target_actions_str, predicted_actions_str, average='macro')\n",
    "\n",
    "# Calculate the micro F1 score\n",
    "micro_f1 = f1_score(target_actions_str, predicted_actions_str, average='micro')\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "print(\"Micro F1 Score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.arange(16, 28.5, 0.5)\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "for target, prediction in zip(target_actions, predicted_actions):\n",
    "    if target == prediction:\n",
    "        correct_pred[target] += 1\n",
    "    total_pred[target] += 1\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    if total_pred[classname] > 0:\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    else:\n",
    "        accuracy = 0\n",
    "    print(f'Accuracy for class: {classname} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Calculate and display the classification report for each class\n",
    "class_names = sorted(np.unique(train_actions_str))\n",
    "report = classification_report(target_actions_str, predicted_actions_str, target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for three datasets\n",
    "data1 = train_action_count_dict.values()\n",
    "data4 = val_action_count_dict.values()\n",
    "data2 = target_action_count_dict.values()\n",
    "data3 = predicted_action_count_dict.values()\n",
    "\n",
    "# Define the x-axis labels for the bars\n",
    "x_labels = train_action_count_dict.keys()\n",
    "\n",
    "# Create a figure and three subplots side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "\n",
    "# Plot the bar plots on each subplot\n",
    "bar_width = 1\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "# Bar plot for Dataset 1\n",
    "axes[0].bar(x, data1, bar_width, color='blue', label='train actions', edgecolor='black', alpha=0.5)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(x_labels, rotation=90)\n",
    "axes[0].set_title('Target temperature from train dataset')\n",
    "\n",
    "# Bar plot for Dataset 4\n",
    "axes[1].bar(x, data4, bar_width, color='purple', label='predicted actions', edgecolor='black', alpha=0.5)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(x_labels, rotation=90)\n",
    "axes[1].set_title('Target temperature from the the validation dataset')\n",
    "\n",
    "# Bar plot for Dataset 2\n",
    "axes[2].bar(x, data2, bar_width, color='green', label='target actions', edgecolor='black', alpha=0.5)\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(x_labels, rotation=90)\n",
    "axes[2].set_title('Target temperature from the test set')\n",
    "\n",
    "# Bar plot for Dataset 3\n",
    "axes[3].bar(x, data3, bar_width, color='red', label='predicted actions', edgecolor='black', alpha=0.5)\n",
    "axes[3].set_xticks(x)\n",
    "axes[3].set_xticklabels(x_labels, rotation=90)\n",
    "axes[3].set_title('Target temperature from the predictions on the test set')\n",
    "\n",
    "\n",
    "\n",
    "# Add labels and title to the overall figure\n",
    "plt.suptitle('Bar Plots of Train, Eval and Predicted target temperatures')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/temp.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_probabilities(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    total_counts = len(labels)\n",
    "    probabilities = counts / total_counts\n",
    "    return unique_labels, probabilities\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "\n",
    "# Compute probabilities and unique labels for each list\n",
    "labels1, probabilities1 = compute_probabilities(train_actions_str)\n",
    "labels2, probabilities2 = compute_probabilities(val_actions_str)\n",
    "\n",
    "# Union of unique labels from both lists\n",
    "all_labels = np.union1d(labels1, labels2)\n",
    "\n",
    "# Fill missing labels with zero probabilities\n",
    "probabilities1_all = np.zeros_like(all_labels, dtype=float)\n",
    "probabilities2_all = np.zeros_like(all_labels, dtype=float)\n",
    "probabilities1_all[np.searchsorted(all_labels, labels1)] = probabilities1\n",
    "probabilities2_all[np.searchsorted(all_labels, labels2)] = probabilities2\n",
    "\n",
    "# Compute KL-divergence from list1 to list2\n",
    "kl_divergence_1to2 = kl_divergence(probabilities1_all, probabilities2_all)\n",
    "\n",
    "# Compute KL-divergence from list2 to list1\n",
    "kl_divergence_2to1 = kl_divergence(probabilities2_all, probabilities1_all)\n",
    "\n",
    "print(\"KL-Divergence from list1 to list2:\", kl_divergence_1to2)\n",
    "print(\"KL-Divergence from list2 to list1:\", kl_divergence_2to1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actions = [float(action) for action in train_actions_str]\n",
    "val_actions = [float(action) for action in val_actions_str]\n",
    "\n",
    "print(np.mean(train_actions), np.mean(val_actions))\n",
    "print(np.median(train_actions), np.median(val_actions))\n",
    "print(np.std(train_actions), np.std(val_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "unique_labels = np.unique(np.concatenate((target_actions_str, predicted_actions_str)))\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(target_actions_str, predicted_actions_str, labels=unique_labels)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix for better visualization\n",
    "df_cm = pd.DataFrame(cf_matrix, index=unique_labels, columns=unique_labels)\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "# plt.plot(df_cm)\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues', cbar=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f\"Confusion matrix for {len(train_dataset)} train and {len(predicted_actions)} datapoints\")\n",
    "# plt.show()\n",
    "plt.savefig(f'Figures/Confusion matrix for {len(train_dataset)} train and {len(predicted_actions)} datapoints.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(returns)\n",
    "plt.title(\"Return using sampling from the test env\")\n",
    "plt.show()\n",
    "# plt.savefig(f\"Figures/return_with_sampling_500_train_traj.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sorted(train_actions_str))\n",
    "plt.xlabel('Target Temperatures')\n",
    "plt.title(\"Target Temperature distribution in the training set\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sorted(target_actions_str))\n",
    "plt.xlabel('Target temperature')\n",
    "plt.title(\"Target temperatures distribution in the evaluation set\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sorted(predicted_actions_str))\n",
    "plt.xlabel('Target temperatures from the evaluation set')\n",
    "plt.title(\"Predicted target temperatures distribution from the evaluation set\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numbers of pairs of bars you want\n",
    "# # N = 4\n",
    "\n",
    "# # Data on X-axis\n",
    "\n",
    "# # Specify the values of blue bars (height)\n",
    "# # train_actions = list(train_action_count_dict.values())\n",
    "# target_actions = list(target_action_count_dict.values())\n",
    "\n",
    "\n",
    "# # Specify the values of orange bars (height)\n",
    "# pred_actions = list(predicted_action_count_dict.values())\n",
    "\n",
    "\n",
    "# print(len(target_actions), len(pred_actions))\n",
    "# # Position of bars on x-axis\n",
    "# ind = np.arange(16.0, 28.5, 0.5)\n",
    "# # ind = np.arange(5)\n",
    "# # print(ind)\n",
    "\n",
    "# # Figure size\n",
    "# plt.figure(figsize=(10,5))\n",
    "\n",
    "# # Width of a bar \n",
    "# width = 0.2       \n",
    "\n",
    "# # Plotting\n",
    "# plt.bar(ind, target_actions , width, label='target action')\n",
    "# plt.bar(ind + width, pred_actions, width, label='pred action')\n",
    "\n",
    "# plt.xlabel('Actions')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Action distribution comparison between target and predictions')\n",
    "\n",
    "# # # xticks()\n",
    "# # # First argument - A list of positions at which ticks should be placed\n",
    "# # # Second argument -  A list of labels to place at the given locations\n",
    "# # plt.xticks(ind+0.1, train_action_count_dict.keys())\n",
    "# plt.xticks(ind+0.1, ind)\n",
    "\n",
    "# # Finding the best position for legends and putting it\n",
    "# plt.legend(loc='best')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from your_pytorch_model import YourModel  # Import your PyTorch model\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters to be tuned by Optuna\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    num_hidden_units = trial.suggest_int('num_hidden_units', 32, 256)\n",
    "    \n",
    "    # Load the val_dataset\n",
    "    val_data_dir = \"../atari/data-for-dt/smart-climate-val-trajectories-v2.pkl\"\n",
    "    # Create the dataset first\n",
    "    obss, actions, returns, done_idxs, rtgs, timesteps = create_dataset(val_data_dir, total_trajectories=8000, apply_dim_reduction=True)\n",
    "    \n",
    "    # Split your data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(obss, actions, test_size=0.1, random_state=123)\n",
    "    \n",
    "    val_dataset = StateActionReturnDataset(X_train, args.context_length*3, y_train, done_idxs, rtgs, timesteps)\n",
    "    print(f\"vocab size: {val_dataset.vocab_size}\")\n",
    "    \n",
    "    # Define the model here\n",
    "    mconf = GPTConfig(val_dataset.vocab_size, val_dataset.block_size, n_layer=6, n_head=8, n_embd=128, model_type=args.model_type, max_timestep=max(timesteps), input_dim=len(obss[0]))\n",
    "    model = GPT(mconf)\n",
    "\n",
    "    # Train the model for a fixed number of epochs\n",
    "    epochs = 10\n",
    "    tconf = TrainerConfig(max_epochs=epochs, batch_size=args.batch_size, learning_rate=6e-4, lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*args.context_length*3, num_workers=4, seed=args.seed, model_type=args.model_type, env=args.env, max_timestep=max(timesteps))\n",
    "    \n",
    "    rtg = 100\n",
    "    max_ep_len = 100\n",
    "    trainer = Trainer(model, train_dataset, None, tconf, args.env, rtg=rtg, max_ep_len=max_ep_len, num_eval_episodes=1)\n",
    "    \n",
    "    trainer.train()\n",
    "    val_loss, val_accuracy = trainer.evaluate_model()\n",
    "\n",
    "    # Return the validation loss as the objective value to be minimized\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "learning_rate = best_params['learning_rate']\n",
    "num_hidden_units = best_params['num_hidden_units']\n",
    "learning_rate, num_hidden_units\n",
    "# # Train your final model using the best hyperparameters\n",
    "# final_model = model(num_hidden_units)\n",
    "# optimizer = optim.Adam(final_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model on the entire training data\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the val_dataset\n",
    "val_data_dir = \"../atari/data-for-dt/smart-climate-val-trajectories-v2.pkl\"\n",
    "# Create the dataset first\n",
    "obss, actions, returns, done_idxs, rtgs, timesteps = create_dataset(val_data_dir, total_trajectories=8000, apply_dim_reduction=True)\n",
    "# Sanity check\n",
    "# Are there any nan values in the obss\n",
    "print(f\"There are nan values in the obss: {np.isnan(np.array(obss)).any()}\")\n",
    "print(\"*\" * len(args.env + \"Environment\"))\n",
    "print(f\"{args.env} Environment\")\n",
    "print(\"*\" * len(args.env + \"Environment\"))\n",
    "print(f\"total obss: {len(obss)}\\ntotal actions: {actions.shape}\\ntotal returns: {returns.shape}\\ntimesteps: {len(timesteps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = StateActionReturnDataset(obss, args.context_length*3, actions, done_idxs, rtgs, timesteps)\n",
    "print(f\"vocab size: {train_dataset.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a trainer instance and kick off training\n",
    "epochs = 10\n",
    "tconf = TrainerConfig(max_epochs=epochs, batch_size=args.batch_size, learning_rate=6e-4, lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*args.context_length*3, num_workers=4, seed=args.seed, model_type=args.model_type, env=args.env, max_timestep=max(timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg = 100\n",
    "max_ep_len = 100\n",
    "trainer = Trainer(model, train_dataset, None, tconf, args.env, rtg=rtg, max_ep_len=max_ep_len, num_eval_episodes=10)\n",
    "# avg_return, predicted_actions, target_actions, epoch_losses = trainer.train()\n",
    "# print(f\"Average reward achieved: {avg_return:.2f} with RTG: {rtg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision-transformer-atari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
